{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import json,pickle\n",
    "\n",
    "dataset = 'Stitch'\n",
    "# load dataset\n",
    "dataset_path = 'data/' + dataset + '/'\n",
    "\n",
    "# train_fold_origin = json.load(open(dataset_path + 'folds/train_fold_setting1.txt'))\n",
    "# train_fold_origin = [e for e in train_fold_origin]  # for 5 folds\n",
    "\n",
    "ligands = json.load(open(dataset_path + 'ligands_can.txt'), object_pairs_hook=OrderedDict)\n",
    "proteins = json.load(open(dataset_path + 'proteins.txt'), object_pairs_hook=OrderedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165366"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs = []\n",
    "# drug_smiles = []\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "# RDLogger.DisableLog('rdApp.*')\n",
    "# # smiles\n",
    "# for d in ligands.keys():\n",
    "#     lg = Chem.MolToSmiles(Chem.MolFromSmiles(ligands[d]), isomericSmiles=True)\n",
    "#     drugs.append(lg)\n",
    "#     drug_smiles.append(ligands[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one ont encoding\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        # print(x)\n",
    "        raise Exception('input {0} not in allowable set{1}:'.format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    '''Maps inputs not in the allowable set to the last element.'''\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "    \n",
    "# mol atom feature for mol graph\n",
    "def atom_features(atom):\n",
    "    # 44 +11 +11 +11 +1\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
    "                                          ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na', 'Ca', 'Fe', 'As',\n",
    "                                           'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se',\n",
    "                                           'Ti', 'Zn', 'H', 'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr',\n",
    "                                           'Pt', 'Hg', 'Pb', 'X']) +\n",
    "                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "                    [atom.GetIsAromatic()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol smile to mol graph edge index\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "def smile_to_graph(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "\n",
    "    c_size = mol.GetNumAtoms()\n",
    "\n",
    "    features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        feature = atom_features(atom)\n",
    "        features.append(feature / sum(feature))\n",
    "\n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    g = nx.Graph(edges).to_directed()\n",
    "    edge_index = []\n",
    "    mol_edge_weight=[]\n",
    "    mol_adj = np.zeros((c_size, c_size))\n",
    "    for e1, e2 in g.edges:\n",
    "        mol_adj[e1, e2] = 1\n",
    "        # edge_index.append([e1, e2])\n",
    "    mol_adj += np.matrix(np.eye(mol_adj.shape[0]))\n",
    "    index_row, index_col = np.where(mol_adj >= 0.5)\n",
    "    for i, j in zip(index_row, index_col):\n",
    "        edge_index.append([i, j])\n",
    "        mol_edge_weight.append([1])\n",
    "    # print('smile_to_graph')\n",
    "    # print(np.array(features).shape)\n",
    "    return c_size, features, edge_index,mol_edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14min\n",
    "# compound_iso_smiles = drugs\n",
    "\n",
    "# create smile graph\n",
    "# smile_graph = {}\n",
    "# i = 0\n",
    "# for smile in compound_iso_smiles:\n",
    "#     g = smile_to_graph(smile)\n",
    "#     smile_graph[smile] = g\n",
    "#     if i%1000==0:\n",
    "#         print(i)\n",
    "#     i+=1\n",
    "with open('data/Stitch/temp/smile_graph.pickle','rb') as f:\n",
    "    smile_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# esm_emb_path = 'data/' + dataset + '/protein_emb/UniRef50_'\n",
    "# protein_dict = json.load(open('data/Stitch/proteins.txt'))\n",
    "# target_reps_dict = {}\n",
    "# i=0\n",
    "# for key in proteins.keys():\n",
    "#     target_reps_dict[protein_dict[key]] = torch. load(esm_emb_path+ key + '.pt')['mean_representations'][36]\n",
    "#     if i%1000==0:\n",
    "#         print(i)\n",
    "#     i+=1\n",
    "\n",
    "# with open('data/Stitch/temp/protein_rep.pickle','wb') as handle:\n",
    "#     pickle.dump(target_reps_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('data/Stitch/temp/protein_rep.pickle', 'rb') as handle:\n",
    "    target_reps_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_reps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch_geometric.data import InMemoryDataset, DataLoader, Batch\n",
    "from torch_geometric import data as DATA\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# initialize the dataset\n",
    "class DTADataset(InMemoryDataset):\n",
    "    def __init__(self, root='/tmp', dataset='davis',\n",
    "                 xd=None, y=None, transform= None,\n",
    "                 pre_transform=None, smile_graph=None, target_key=None, target_rep=None):\n",
    "        super(DTADataset, self).__init__(root, transform, pre_transform)\n",
    "        self.dataset = dataset\n",
    "        self.process(xd, target_key, y, smile_graph, target_rep)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        pass\n",
    "        # return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [self.dataset + '_data_mol.pt', self.dataset + '_data_pro.pt']\n",
    "\n",
    "    def _process(self):\n",
    "        if not os.path.exists(self.processed_dir):\n",
    "            os.makedirs(self.processed_dir)\n",
    "\n",
    "    def process(self, xd, target_key, y, smile_graph, target_rep):\n",
    "        assert (len(xd) == len(target_key) and len(xd) == len(y)), 'The three lists must be the same length!'\n",
    "        data_list_mol = []\n",
    "        data_list_pro = []\n",
    "        data_len = len(xd)\n",
    "        for i in range(data_len):\n",
    "            entity1 = xd[i]\n",
    "            # print(torch.Tensor(target_rep[target_key[i]][36]))\n",
    "            # print(torch.FloatTensor(y[i]).shape)\n",
    "            # torch.from_numpy\n",
    "            labels = y[i]\n",
    "            # print(labels,torch.FloatTensor([labels]),torch.FloatTensor([labels]).shape)\n",
    "            \n",
    "            # labels = torch.concat((torch.FloatTensor([labels]),torch.Tensor(target_rep[target_key[i]][36])))\n",
    "            # print(labels)\n",
    "            # print(labels.shape)\n",
    "            # print('DTI')\n",
    "            # convert SMILES to molecular representation using rdkit\n",
    "            if entity1 in smile_graph.keys():\n",
    "                c_size, features, edge_index,edge_weight = smile_graph[entity1]\n",
    "            else:\n",
    "                # print('graph not found')\n",
    "                c_size, features, edge_index,edge_weight = smile_to_graph(entity1)\n",
    "                # print('complete')\n",
    "            # print(target_features.shape, target_edge_index.shape)\n",
    "            # make the graph ready for PyTorch Geometrics GCN algorithms:\n",
    "            GCNData_mol = DATA.Data(x=torch.Tensor(np.array(features)),\n",
    "                                    edge_index=torch.LongTensor(edge_index).transpose(1, 0),\n",
    "                                    y=torch.FloatTensor([labels])\n",
    "                                    )\n",
    "            GCNData_mol.__setitem__('c_size', torch.LongTensor([c_size]))\n",
    "            data_list_mol.append(GCNData_mol)\n",
    "\n",
    "            data_list_pro.append(torch.Tensor(target_rep[target_key[i]]))\n",
    "            if i%10000==0:\n",
    "                print(i)\n",
    "            # print(data_list_mol,data_list_pro)\n",
    "   \n",
    "            \n",
    "        if self.pre_filter is not None:\n",
    "            data_list_mol = [data for data in data_list_mol if self.pre_filter(data)]\n",
    "        if self.pre_transform is not None:\n",
    "            data_list_mol = [self.pre_transform(data) for data in data_list_mol]\n",
    "        self.data_mol = data_list_mol\n",
    "        self.data_pro = data_list_pro\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_mol)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_mol[idx], self.data_pro[idx]\n",
    "        \n",
    "def collate(batch):\n",
    "    graphs = Batch.from_data_list([item[0] for item in batch])\n",
    "    tensors = [item[1] for item in batch]\n",
    "    tensors = torch.stack(tensors)\n",
    "\n",
    "    return graphs,tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n"
     ]
    }
   ],
   "source": [
    "df_train_fold = pd.read_csv('data/' + dataset + '/'+ dataset+'_' + 'train' + '.csv')\n",
    "train_drugs, train_prot_keys, train_Y = list(df_train_fold['compound_iso_smiles']), list(df_train_fold['target_sequence']), list(df_train_fold['affinity'])\n",
    "train_drugs, train_prot_keys, train_Y = np.asarray(train_drugs), np.asarray(train_prot_keys), np.asarray(train_Y)\n",
    "\n",
    "train_dataset = DTADataset(root='data', dataset=dataset + '_' + 'train', xd=train_drugs, target_key=train_prot_keys,\n",
    "                            y=train_Y, smile_graph=smile_graph, target_rep=target_reps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DTADataset(818602)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "datasets = ['davis', 'kiba','Stitch']\n",
    "\n",
    "cuda_name = 'cuda:0'\n",
    "print('cuda_name:', cuda_name)\n",
    "fold = [0, 1, 2, 3, 4][0]\n",
    "cross_validation_flag = True\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "TEST_BATCH_SIZE = 512\n",
    "LR = 0.001\n",
    "NUM_EPOCHS = 300\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data,valid_data=train_test_split(train_dataset,shuffle=True,test_size=0.2)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True,num_workers=8,\n",
    "                                            collate_fn=collate)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=TEST_BATCH_SIZE, shuffle=False,num_workers=4,\n",
    "                                            collate_fn=collate)\n",
    "                                            \n",
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import TransformerConv,GATConv, GCNConv,global_max_pool as gmp, global_add_pool as gap,global_mean_pool as gep,global_sort_pool\n",
    "from torch_geometric.utils import dropout_adj\n",
    "\n",
    "\n",
    "\n",
    "# GCN based model\n",
    "class GNNNet(torch.nn.Module):\n",
    "    def __init__(self, n_output=1, num_features_pro=54, num_features_mol=78, output_dim=128, dropout=0.2):\n",
    "        super(GNNNet, self).__init__()\n",
    "\n",
    "        print('GNNNet Loaded')\n",
    "        self.n_output = n_output\n",
    "        self.mol_conv1 = TransformerConv(num_features_mol, num_features_mol)\n",
    "        self.mol_conv2 = TransformerConv(num_features_mol, num_features_mol * 2)\n",
    "        self.mol_conv3 = TransformerConv(num_features_mol * 2, num_features_mol * 4)\n",
    "        self.mol_fc_g1 = torch.nn.Linear(num_features_mol * 4, 1024)\n",
    "        self.mol_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "        # self.pro_conv1 = GCNConv(embed_dim, embed_dim)\n",
    "        # self.pro_conv1 = GCNConv(num_features_pro, num_features_pro)\n",
    "\n",
    "        # self.pro_conv4 = GCNConv(embed_dim * 4, embed_dim * 8)\n",
    "        self.pro_fc_g1 = torch.nn.Linear(num_features_pro, 1024)\n",
    "        self.pro_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # combined layers\n",
    "        self.fc1 = nn.Linear(2688, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.out = nn.Linear(512, self.n_output)\n",
    "\n",
    "    def forward(self, data_mol, data_pro):\n",
    "        # get graph input\n",
    "        mol_x, mol_edge_index, mol_batch = data_mol.x, data_mol.edge_index, data_mol.batch\n",
    "        # get protein input\n",
    "        # target_x, target_edge_index, target_batch = data_pro.x, data_pro.edge_index, data_pro.batch\n",
    "\n",
    "        # target_seq=data_pro.target\n",
    "\n",
    "        # print('size')\n",
    "        # print('mol_x', mol_x.size(), 'edge_index', mol_edge_index.size(), 'batch',mol_batch, mol_batch.size())\n",
    "        # print('target_x', target_x.size(), 'target_edge_index', target_edge_index,target_edge_index.size(), 'batch',target_batch, target_batch.size())\n",
    "\n",
    "        x = self.mol_conv1(mol_x, mol_edge_index)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # mol_edge_index, _ = dropout_adj(mol_edge_index, training=self.training)\n",
    "        x = self.mol_conv2(x, mol_edge_index)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # mol_edge_index, _ = dropout_adj(mol_edge_index, training=self.training)\n",
    "        x = self.mol_conv3(x, mol_edge_index)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = gep(x, mol_batch)  # global pooling\n",
    "\n",
    "        # flatten\n",
    "        x = self.relu(self.mol_fc_g1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.mol_fc_g2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # # xt = self.pro_conv1(target_x, target_edge_index)\n",
    "        # xt = self.relu(xt)\n",
    "        # xt = gep(xt, target_batch)  # global pooling\n",
    "\n",
    "        # # flatten\n",
    "        # xt = self.relu(self.pro_fc_g1(xt))\n",
    "        # xt = self.dropout(xt)\n",
    "        # xt = self.pro_fc_g2(xt)\n",
    "        # xt = self.dropout(xt)\n",
    "\n",
    "        # print(x.size(), xt.size())\n",
    "        # concat\n",
    "        xc = torch.cat((x, data_pro), 1)\n",
    "        # add some dense layers\n",
    "        xc = self.fc1(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        xc = self.fc2(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        out = self.out(xc)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epochs:  300\n",
      "GNNNet Loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Learning rate: ', LR)\n",
    "print('Epochs: ', NUM_EPOCHS)\n",
    "\n",
    "models_dir = 'models'\n",
    "results_dir = 'results'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# Main program: iterate over different datasets\n",
    "result_str = ''\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(cuda_name if USE_CUDA else 'cpu')\n",
    "model = GNNNet()\n",
    "model.to(device)\n",
    "\n",
    "model_st = GNNNet.__name__\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function at each epoch\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    print('Training on {} samples...'.format(len(train_loader.dataset)))\n",
    "    model.train()\n",
    "    LOG_INTERVAL = 100\n",
    "    TRAIN_BATCH_SIZE = 512\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data_mol = data[0].to(device)\n",
    "        # data_mol = [item.to(device) for item in data[0]]\n",
    "        # data_mol = data[0].to(device)\n",
    "        data_pro = data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(data_mol, data_pro)\n",
    "            # print(data_mol)\n",
    "            # print(data_mol.y)\n",
    "            # labels= [sample.y.float().to(device) for sample in data_mol]\n",
    "            # labels=torch.stack(labels).view(-1, 1)\n",
    "            labels = data_mol.y.view(-1, 1)\n",
    "            # print(output.shape,labels.shape)\n",
    "            loss = loss_fn(output, labels)\n",
    "        #loss.backward()\n",
    "        scaler.scale(loss).backward()\n",
    "        wandb.log({\"loss per batch\": loss})\n",
    "        #optimizer.step()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n",
    "                                                                           batch_idx * TRAIN_BATCH_SIZE,\n",
    "                                                                           len(train_loader.dataset),\n",
    "                                                                           100. * batch_idx / len(train_loader),\n",
    "                                                                           loss.item()))\n",
    "\n",
    "# predict\n",
    "def predicting(model, device, loader):\n",
    "    model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data_mol = data[0].to(device)\n",
    "            data_pro = data[1].to(device)\n",
    "            output = model(data_mol, data_pro)\n",
    "            labels = data_mol.y.view(-1, 1)\n",
    "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
    "\n",
    "            total_labels = torch.cat((total_labels, labels.cpu()), 0)\n",
    "    return total_labels.numpy().flatten(), total_preds.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1xhyw7ls) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss per batch</td><td>▅█▅▅▄▆▆▇▆▃▄▄▄▂▅▆▃▅▇▁▅▅▆▅▆▃▅▇▃▄█▃▅▄▃▅▇▁▃▄</td></tr><tr><td>test_ci</td><td>▁█</td></tr><tr><td>test_mse</td><td>█▁</td></tr><tr><td>test_pc</td><td>▁█</td></tr><tr><td>val_ci</td><td>▁▅█</td></tr><tr><td>val_mse</td><td>█▅▁</td></tr><tr><td>val_pc</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss per batch</td><td>1.88305</td></tr><tr><td>test_ci</td><td>0.62117</td></tr><tr><td>test_mse</td><td>1.56598</td></tr><tr><td>test_pc</td><td>0.44533</td></tr><tr><td>val_ci</td><td>0.62084</td></tr><tr><td>val_mse</td><td>1.58015</td></tr><tr><td>val_pc</td><td>0.44559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cosmic-dew-173</strong>: <a href=\"https://wandb.ai/daga06/my-dgraphdta-resrt-project/runs/1xhyw7ls\" target=\"_blank\">https://wandb.ai/daga06/my-dgraphdta-resrt-project/runs/1xhyw7ls</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230209_032233-1xhyw7ls/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1xhyw7ls). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/wandb/run-20230209_032852-1f3e160l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/daga06/my-dgraphdta-resrt-project/runs/1f3e160l\" target=\"_blank\">desert-elevator-174</a></strong> to <a href=\"https://wandb.ai/daga06/my-dgraphdta-resrt-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/daga06/my-dgraphdta-resrt-project/runs/1f3e160l?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f14ee7346d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import DataLoader\n",
    "import wandb\n",
    "wandb.init(project=\"my-dgraphdta-resrt-project\", entity=\"daga06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All metrics\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from emetrics import get_aupr, get_cindex, get_rm2, get_ci, get_mse, get_rmse, get_pearson, get_spearman\n",
    "# from utils import *\n",
    "from scipy import stats\n",
    "# from gnn import GNNNet\n",
    "from data_process import create_dataset_for_test\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = torch.load(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "import time\n",
    "def calculate_metrics(Y, P, dataset='davis'):\n",
    "    # # aupr = get_aupr(Y, P)\n",
    "    # t = time.time()\n",
    "    \n",
    "    \n",
    "    # cindex = get_cindex(Y, P)\n",
    "    # print(cindex)\n",
    "    # print(concordance_index(Y, P))  # DeepDTAget_cindex(Y, P)\n",
    "    \n",
    "    \n",
    "    cindex2 = concordance_index(Y, P)  # GraphDTA\n",
    "    # rm2 = get_rm2(Y, P)  # DeepDTA\n",
    "    mse = get_mse(Y, P)\n",
    "    # t2 = time.time()\n",
    "    pearson = get_pearson(Y, P)\n",
    "    # t3 = time.time()\n",
    "    # spearman = get_spearman(Y, P)\n",
    "    # rmse = get_rmse(Y, P)\n",
    "\n",
    "    print('metrics for ', dataset)\n",
    "    # print('aupr:', aupr)\n",
    "    # print('cindex:', cindex)\n",
    "    print('cindex2', cindex2)\n",
    "    # print('rm2:', rm2)\n",
    "    print('mse:', mse)\n",
    "    print('pearson', pearson)\n",
    "    # print(t - t1,t2-t1,t3-t2)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # result_file_name = 'results/result_' + model_st + '_' + dataset + '.txt'\n",
    "    result_str = ''\n",
    "    result_str += dataset + '\\r\\n'\n",
    "    result_str += ' ' + ' mse:' + str(mse) + ' ' + ' pearson:' + str(pearson) + ' '+ ' ' + 'ci:' + str(cindex2)\n",
    "    print(result_str)\n",
    "    # open(result_file_name, 'w').writelines(result_str)\n",
    "    return mse,cindex2,pearson\n",
    "\n",
    "def plot_density(Y, P, fold=0, dataset='davis'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.grid(linestyle='--')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.scatter(P, Y, color='blue', s=40)\n",
    "    plt.title('density of ' + dataset, fontsize=30, fontweight='bold')\n",
    "    plt.xlabel('predicted', fontsize=30, fontweight='bold')\n",
    "    plt.ylabel('measured', fontsize=30, fontweight='bold')\n",
    "    # plt.xlim(0, 21)\n",
    "    # plt.ylim(0, 21)\n",
    "    if dataset == 'davis':\n",
    "        plt.plot([5, 11], [5, 11], color='black')\n",
    "    else:\n",
    "        plt.plot([6, 16], [6, 16], color='black')\n",
    "    # plt.legend()\n",
    "    plt.legend(loc=0, numpoints=1)\n",
    "    leg = plt.gca().get_legend()\n",
    "    ltext = leg.get_texts()\n",
    "    plt.setp(ltext, fontsize=12, fontweight='bold')\n",
    "    plt.savefig(os.path.join('results', dataset + '_' + str(fold) + '.png'), dpi=500, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    # plot_density(Y, P, fold, dataset)\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from math import sqrt\n",
    "from sklearn.metrics import average_precision_score\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def get_aupr(Y, P, threshold=7.0):\n",
    "    # print(Y.shape,P.shape)\n",
    "    Y = np.where(Y >= 7.0, 1, 0)\n",
    "    P = np.where(P >= 7.0, 1, 0)\n",
    "    aupr = average_precision_score(Y, P)\n",
    "    return aupr\n",
    "\n",
    "\n",
    "def get_cindex(Y, P):\n",
    "    summ = 0\n",
    "    pair = 0\n",
    "\n",
    "    for i in range(1, len(Y)):\n",
    "        for j in range(0, i):\n",
    "            if i is not j:\n",
    "                if (Y[i] > Y[j]):\n",
    "                    pair += 1\n",
    "                    summ += 1 * (P[i] > P[j]) + 0.5 * (P[i] == P[j])\n",
    "\n",
    "    if pair != 0:\n",
    "        return summ / pair\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def r_squared_error(y_obs, y_pred):\n",
    "    y_obs = np.array(y_obs)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_obs_mean = [np.mean(y_obs) for y in y_obs]\n",
    "    y_pred_mean = [np.mean(y_pred) for y in y_pred]\n",
    "\n",
    "    mult = sum((y_pred - y_pred_mean) * (y_obs - y_obs_mean))\n",
    "    mult = mult * mult\n",
    "\n",
    "    y_obs_sq = sum((y_obs - y_obs_mean) * (y_obs - y_obs_mean))\n",
    "    y_pred_sq = sum((y_pred - y_pred_mean) * (y_pred - y_pred_mean))\n",
    "\n",
    "    return mult / float(y_obs_sq * y_pred_sq)\n",
    "\n",
    "\n",
    "def get_k(y_obs, y_pred):\n",
    "    y_obs = np.array(y_obs)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return sum(y_obs * y_pred) / float(sum(y_pred * y_pred))\n",
    "\n",
    "\n",
    "def squared_error_zero(y_obs, y_pred):\n",
    "    k = get_k(y_obs, y_pred)\n",
    "\n",
    "    y_obs = np.array(y_obs)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_obs_mean = [np.mean(y_obs) for y in y_obs]\n",
    "    upp = sum((y_obs - (k * y_pred)) * (y_obs - (k * y_pred)))\n",
    "    down = sum((y_obs - y_obs_mean) * (y_obs - y_obs_mean))\n",
    "\n",
    "    return 1 - (upp / float(down))\n",
    "\n",
    "\n",
    "def get_rm2(ys_orig, ys_line):\n",
    "    r2 = r_squared_error(ys_orig, ys_line)\n",
    "    r02 = squared_error_zero(ys_orig, ys_line)\n",
    "\n",
    "    return r2 * (1 - np.sqrt(np.absolute((r2 * r2) - (r02 * r02))))\n",
    "\n",
    "\n",
    "def get_rmse(y, f):\n",
    "    rmse = sqrt(((y - f) ** 2).mean(axis=0))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def get_mse(y, f):\n",
    "    mse = ((y - f) ** 2).mean(axis=0)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def get_pearson(y, f):\n",
    "    rp = np.corrcoef(y, f)[0, 1]\n",
    "    return rp\n",
    "\n",
    "\n",
    "def get_spearman(y, f):\n",
    "    rs = stats.spearmanr(y, f)[0]\n",
    "    return rs\n",
    "\n",
    "\n",
    "def get_ci(y, f):\n",
    "    ind = np.argsort(y)\n",
    "    y = y[ind]\n",
    "    f = f[ind]\n",
    "    i = len(y) - 1\n",
    "    j = i - 1\n",
    "    z = 0.0\n",
    "    S = 0.0\n",
    "    while i > 0:\n",
    "        while j >= 0:\n",
    "            if y[i] > y[j]:\n",
    "                z = z + 1\n",
    "                u = f[i] - f[j]\n",
    "                if u > 0:\n",
    "                    S = S + 1\n",
    "                elif u == 0:\n",
    "                    S = S + 0.5\n",
    "            j = j - 1\n",
    "        i = i - 1\n",
    "        j = i - 1\n",
    "    ci = S / z\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[2]\n",
    "df_test_fold = pd.read_csv('data/' + dataset + '/'+ dataset+'_' + 'test' + '.csv')\n",
    "test_drugs, test_prot_keys, test_Y = list(df_test_fold['compound_iso_smiles']), list(df_test_fold['target_sequence']), list(df_test_fold['affinity'])\n",
    "test_drugs, test_prot_keys, test_Y = np.asarray(test_drugs), np.asarray(test_prot_keys), np.asarray(test_Y)\n",
    "\n",
    "test_data = DTADataset(root='data', dataset=dataset + '_' + 'test', xd=test_drugs, target_key=test_prot_keys,\n",
    "                            y=test_Y, smile_graph=smile_graph, target_rep=target_reps_dict)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False,num_workers=4,\n",
    "                                              collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 654881 samples...\n",
      "Train epoch: 1 [0/654881 (0%)]\tLoss: 1.322493\n"
     ]
    }
   ],
   "source": [
    "#188 minutes\n",
    "best_mse = 1000\n",
    "best_test_mse = 1000\n",
    "best_epoch = -1\n",
    "# model_file_name = 'models/model_' + model_st + '_' + dataset + '_' + str(fold) + '.model'\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, device, train_loader, optimizer, epoch + 1)\n",
    "    print('predicting for valid data')\n",
    "    G, P = predicting(model, device, valid_loader)\n",
    "    val_mse,val_ci,val_pc = calculate_metrics(G, P, dataset)\n",
    "    wandb.log({\"val_ci\": val_ci})\n",
    "    wandb.log({\"val_mse\": val_mse})\n",
    "    wandb.log({\"val_pc\": val_pc})\n",
    "\n",
    "    print('predicting for test data')\n",
    "    \n",
    "    if val_mse < best_mse:\n",
    "        best_mse = val_mse\n",
    "        best_epoch = epoch + 1\n",
    "        # torch.save(model.state_dict(), model_file_name)\n",
    "        print('rmse improved at epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n",
    "    else:\n",
    "        print('No improvement since epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n",
    "    # #reaching optimzation\n",
    "    if epoch>=80: \n",
    "        G, P = predicting(model, device, test_loader)\n",
    "        test_mse,test_ci,test_pc = calculate_metrics(G, P, dataset)\n",
    "        wandb.log({\"test_ci\": test_ci})\n",
    "        wandb.log({\"test_mse\": test_mse})\n",
    "        wandb.log({\"test_pc\": test_pc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DTADataset(818602)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNNet(\n",
       "  (mol_conv1): TransformerConv(78, 78, heads=1)\n",
       "  (mol_conv2): TransformerConv(78, 156, heads=1)\n",
       "  (mol_conv3): TransformerConv(156, 312, heads=1)\n",
       "  (mol_fc_g1): Linear(in_features=312, out_features=1024, bias=True)\n",
       "  (mol_fc_g2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (pro_fc_g1): Linear(in_features=54, out_features=1024, bias=True)\n",
       "  (pro_fc_g2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=2688, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNNet(\n",
       "  (mol_conv1): TransformerConv(78, 78, heads=1)\n",
       "  (mol_conv2): TransformerConv(78, 156, heads=1)\n",
       "  (mol_conv3): TransformerConv(156, 312, heads=1)\n",
       "  (mol_fc_g1): Linear(in_features=312, out_features=1024, bias=True)\n",
       "  (mol_fc_g2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (pro_fc_g1): Linear(in_features=54, out_features=1024, bias=True)\n",
       "  (pro_fc_g2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=2688, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mol_conv1.lin_key.weight',\n",
       "              tensor([[ 0.1240,  0.1045, -0.0059,  ...,  0.0367,  0.0115, -0.0878],\n",
       "                      [-0.2090, -0.1334, -0.0054,  ..., -0.0217, -0.0654,  0.0870],\n",
       "                      [-0.2250, -0.0868,  0.0818,  ...,  0.0653, -0.1036, -0.0764],\n",
       "                      ...,\n",
       "                      [ 0.1865,  0.1649, -0.0717,  ...,  0.0680, -0.0225, -0.1060],\n",
       "                      [-0.7012,  0.3572, -0.0622,  ..., -0.0217,  0.1060,  0.2105],\n",
       "                      [ 0.2170, -0.0510, -0.3284,  ..., -0.0188,  0.0842,  0.0688]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv1.lin_key.bias',\n",
       "              tensor([ 2.6778e-01, -1.8768e-02, -2.4345e-01, -1.6533e-01, -3.3262e-01,\n",
       "                      -2.5063e-01, -2.2554e-01, -8.9362e-01,  2.8967e-01,  2.6792e-01,\n",
       "                       3.0093e-01, -7.1495e-01,  4.9546e-01, -3.9335e-01, -6.7751e-02,\n",
       "                      -5.5899e-02,  2.9631e-01,  1.9461e-01,  5.3106e-02, -6.1868e-01,\n",
       "                       2.4613e-02,  2.8504e-02, -4.2559e-01,  4.0380e-01, -4.1240e-01,\n",
       "                       3.7005e-01, -4.9655e-01,  8.7560e-02, -8.3863e-02, -4.9189e-01,\n",
       "                      -8.4664e-02,  6.7577e-01, -2.7868e-01, -6.9309e-01, -8.8377e-01,\n",
       "                      -6.4478e-01,  3.2518e-01,  4.0519e-02,  4.1337e-01,  6.2666e-01,\n",
       "                      -8.1056e-02,  5.5432e-03, -3.5041e-01,  1.4050e-01, -1.7629e-01,\n",
       "                       2.0589e-01, -1.0436e-02, -3.0658e-01,  9.8894e-02, -2.7445e-01,\n",
       "                      -1.4826e-02, -2.1043e-01,  5.8260e-01,  3.8942e-01,  5.0273e-01,\n",
       "                      -6.3456e-01, -7.0996e-02, -2.7909e-01,  5.0658e-04, -5.8798e-01,\n",
       "                       8.2261e-01,  3.1585e-01, -6.3951e-01, -2.3218e-01, -1.1456e-01,\n",
       "                      -1.1319e+00, -1.9832e-01,  3.2086e-01,  1.9739e-01,  4.2814e-01,\n",
       "                       1.0566e+00,  5.5212e-01, -9.4025e-02, -9.6027e-02, -1.0784e+00,\n",
       "                       1.4683e-01,  1.0108e+00, -1.1444e-02], device='cuda:0')),\n",
       "             ('mol_conv1.lin_query.weight',\n",
       "              tensor([[-0.0734, -0.0582, -0.0923,  ...,  0.0174, -0.1121,  0.0194],\n",
       "                      [ 0.1371,  0.1393,  0.1090,  ...,  0.0027, -0.0676,  0.0027],\n",
       "                      [ 0.1878,  0.0055, -0.0103,  ...,  0.0823,  0.0349, -0.2659],\n",
       "                      ...,\n",
       "                      [-0.1496, -0.1681, -0.3190,  ...,  0.0640,  0.0350, -0.0547],\n",
       "                      [ 0.9732, -0.1816, -0.8111,  ..., -0.0511, -0.0281,  0.5705],\n",
       "                      [-0.3368,  0.1660, -0.1095,  ..., -0.0767, -0.0486, -0.2687]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv1.lin_query.bias',\n",
       "              tensor([ 1.1950e-02, -4.6961e-02, -3.4811e-02, -9.8604e-02,  8.4104e-02,\n",
       "                      -5.9193e-02,  1.3631e-01, -1.8717e-02,  7.7280e-02, -7.9678e-02,\n",
       "                       2.3161e-01,  3.7635e-02,  2.0760e-02, -8.2097e-02, -3.1006e-02,\n",
       "                       5.7999e-02,  1.0890e-01,  5.3837e-02, -6.6146e-02,  8.7802e-03,\n",
       "                      -4.1328e-02, -1.4728e-01,  3.9138e-02,  1.5783e-01, -8.8609e-02,\n",
       "                      -5.7666e-03,  4.5900e-02,  1.4681e-01,  1.1354e-01,  3.0281e-02,\n",
       "                      -8.1386e-02, -4.6621e-02,  8.5832e-02, -1.6615e-01,  6.4754e-02,\n",
       "                       4.7670e-02,  3.0194e-02,  3.1090e-02,  3.4654e-03,  9.5708e-02,\n",
       "                      -5.5519e-02,  7.1713e-02,  5.1502e-02,  1.3427e-01,  1.0572e-01,\n",
       "                      -7.8149e-02, -1.1312e-01,  5.3795e-02,  1.1402e-01, -1.0468e-01,\n",
       "                      -5.6141e-02, -1.5708e-02,  1.0627e-01,  1.0228e-01, -8.3846e-02,\n",
       "                      -2.1968e-02, -7.7344e-02,  1.3181e-01,  1.1319e-01, -7.8310e-02,\n",
       "                      -1.2265e-01, -6.0258e-02,  2.7836e-02,  6.7711e-02, -3.3180e-02,\n",
       "                       6.8629e-02,  1.4388e-01, -2.1994e-02,  1.0244e-02,  1.1072e-01,\n",
       "                      -4.4350e-03, -1.5240e-04,  1.0917e-01,  7.4582e-02, -8.7237e-02,\n",
       "                       3.3418e-02,  1.0919e-01,  1.0556e-02], device='cuda:0')),\n",
       "             ('mol_conv1.lin_value.weight',\n",
       "              tensor([[-2.0028e-01,  4.1647e-01,  5.9991e-02,  ...,  2.7646e-02,\n",
       "                        3.3609e-02,  1.5438e-01],\n",
       "                      [ 3.0006e-01, -2.9343e-01, -3.7339e-01,  ..., -7.1543e-02,\n",
       "                        3.6667e-04, -1.8515e-01],\n",
       "                      [ 1.5994e-02,  5.6757e-02,  6.5991e-02,  ..., -5.0880e-02,\n",
       "                        1.0611e-01, -8.0621e-02],\n",
       "                      ...,\n",
       "                      [ 6.2076e-02, -9.0409e-02, -4.1944e-02,  ...,  8.0400e-03,\n",
       "                        5.3806e-03,  1.1297e-01],\n",
       "                      [-2.9135e-01,  1.0307e+00, -7.7632e-02,  ..., -5.5416e-02,\n",
       "                       -5.1826e-02, -4.3812e-01],\n",
       "                      [-3.5049e-01,  4.5925e-02,  2.2253e-01,  ...,  5.2620e-02,\n",
       "                        2.2158e-02, -1.1652e+00]], device='cuda:0')),\n",
       "             ('mol_conv1.lin_value.bias',\n",
       "              tensor([ 0.0283, -0.0160, -0.0156, -0.1075, -0.0445,  0.0291, -0.0155, -0.0394,\n",
       "                       0.0063,  0.0414, -0.0601, -0.0509, -0.0549, -0.0245, -0.1025,  0.0270,\n",
       "                      -0.0282, -0.0091, -0.0276, -0.1395, -0.1093, -0.1053,  0.0227, -0.0332,\n",
       "                      -0.1139,  0.0364,  0.0244,  0.1157, -0.0197, -0.0319,  0.0969,  0.0147,\n",
       "                       0.1185,  0.0884, -0.1257, -0.0321,  0.0927,  0.0350,  0.0284,  0.0774,\n",
       "                       0.0058, -0.0270,  0.0103, -0.0228, -0.0197,  0.0012, -0.0330, -0.0437,\n",
       "                       0.0090,  0.0972, -0.0905, -0.0219, -0.0708, -0.0194, -0.0986,  0.0478,\n",
       "                      -0.1221, -0.0750, -0.1000, -0.0994,  0.0815,  0.0422,  0.0356, -0.0528,\n",
       "                       0.0646, -0.1595,  0.0580, -0.0943,  0.0219, -0.0260,  0.0195, -0.0421,\n",
       "                       0.0189, -0.0055,  0.0205, -0.0700, -0.0418,  0.0986], device='cuda:0')),\n",
       "             ('mol_conv1.lin_skip.weight',\n",
       "              tensor([[-4.0166e-01,  3.8125e-01, -1.9412e-01,  ...,  3.5906e-02,\n",
       "                       -1.6835e-02, -1.7596e-01],\n",
       "                      [ 8.7919e-02, -5.2709e-01, -2.7568e-01,  ...,  1.6824e-02,\n",
       "                       -8.5986e-02, -2.0176e-01],\n",
       "                      [ 9.8073e-02, -8.2685e-02,  5.0547e-02,  ..., -2.1724e-02,\n",
       "                        2.1897e-02,  1.0777e-01],\n",
       "                      ...,\n",
       "                      [-1.9486e-02, -3.9616e-02, -1.4171e-02,  ...,  3.9568e-02,\n",
       "                       -4.4207e-03,  8.6035e-02],\n",
       "                      [ 1.1141e-01,  3.5628e-01, -2.5600e-01,  ..., -1.0338e-01,\n",
       "                       -1.7746e-04,  1.9563e-01],\n",
       "                      [-2.1331e-01,  4.3781e-03, -1.8323e-01,  ...,  6.9132e-02,\n",
       "                       -1.0701e-01, -1.1929e-01]], device='cuda:0')),\n",
       "             ('mol_conv1.lin_skip.bias',\n",
       "              tensor([-0.1060,  0.0021, -0.0096,  0.0905, -0.0173, -0.0195,  0.0460, -0.0890,\n",
       "                      -0.1405, -0.1194, -0.0273,  0.0067,  0.0002,  0.0500,  0.0265, -0.0791,\n",
       "                      -0.0866,  0.0193, -0.0073, -0.0062, -0.0200,  0.0075, -0.0173, -0.0480,\n",
       "                       0.0565, -0.1023,  0.0079, -0.0156, -0.1063,  0.1174, -0.0405,  0.0137,\n",
       "                      -0.0836, -0.0052, -0.0476, -0.0998, -0.0207,  0.0447,  0.1067, -0.0382,\n",
       "                       0.0406, -0.0314, -0.0392, -0.0388, -0.0288,  0.0789, -0.0166,  0.0806,\n",
       "                      -0.0029,  0.0102, -0.0165, -0.0565, -0.0204,  0.0214,  0.0418, -0.0095,\n",
       "                       0.0527,  0.0630, -0.0564,  0.0687,  0.0229, -0.0895, -0.1168, -0.0017,\n",
       "                       0.0125, -0.0494, -0.0039, -0.0154, -0.0384,  0.0934,  0.0073,  0.1242,\n",
       "                      -0.1123, -0.0986, -0.0253, -0.1132,  0.0012, -0.0697], device='cuda:0')),\n",
       "             ('mol_conv2.lin_key.weight',\n",
       "              tensor([[ 0.3384, -0.3149,  0.0357,  ...,  0.0961,  0.4012, -0.0506],\n",
       "                      [ 0.0593,  0.0960,  0.0745,  ..., -0.0572, -0.1425,  0.7143],\n",
       "                      [-0.1461, -0.3000, -0.0505,  ..., -0.0333,  0.5554,  0.3449],\n",
       "                      ...,\n",
       "                      [ 0.0454, -0.1958,  0.1090,  ..., -0.0046, -0.3337, -0.2741],\n",
       "                      [ 0.3622,  0.0316, -0.0215,  ...,  0.0603,  0.0698,  0.1577],\n",
       "                      [ 0.0780, -0.2588, -0.0595,  ..., -0.0357,  0.6142,  0.1362]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv2.lin_key.bias',\n",
       "              tensor([ 1.0129e-01, -5.8064e-01, -3.6721e-01,  1.9791e-01,  1.6354e-01,\n",
       "                      -1.2385e+00, -4.2791e-01,  7.5363e-02,  1.3711e-01,  5.0486e-01,\n",
       "                      -6.3359e-01,  1.0334e-01, -8.2180e-01,  1.0667e-01,  6.0021e-01,\n",
       "                      -1.0490e+00, -1.0233e-01,  2.2068e-01,  4.0551e-01,  7.9845e-01,\n",
       "                      -7.6266e-02,  7.7209e-01,  8.0322e-02,  1.2981e-01, -9.4279e-01,\n",
       "                       8.0432e-01, -3.6934e-01,  6.6325e-01,  1.1621e-02,  2.5570e-01,\n",
       "                      -2.5901e-02, -3.0580e-01, -5.4649e-01,  4.7877e-01,  2.5212e-01,\n",
       "                      -1.0992e+00,  6.9245e-01,  8.5935e-04, -1.2057e-01,  1.0241e+00,\n",
       "                      -4.5929e-01, -8.5216e-01,  2.5896e-01,  1.9882e-01, -4.4179e-01,\n",
       "                       4.9812e-01, -4.3583e-01,  1.0453e+00,  5.7572e-01, -2.8544e-01,\n",
       "                       6.3363e-02,  7.9905e-02, -8.3483e-01,  4.9845e-01,  5.0288e-02,\n",
       "                       4.1265e-01, -4.5119e-01,  2.7845e-01, -2.0388e-01, -4.8881e-01,\n",
       "                      -2.9615e-01, -5.1073e-02, -2.7147e-01,  1.4881e-01, -7.8509e-01,\n",
       "                      -4.9921e-01, -2.2705e-01, -1.1119e+00, -1.1356e-02,  6.0538e-03,\n",
       "                      -1.9849e-01, -1.5713e-01,  1.1310e+00, -4.3032e-01,  3.0309e-01,\n",
       "                       3.9283e-01, -5.7184e-01,  2.2024e-01, -9.8606e-01,  3.2266e-01,\n",
       "                      -4.7643e-01, -3.1892e-01, -8.2476e-03, -5.5489e-01,  8.5750e-01,\n",
       "                       2.6408e-01,  2.9350e-01, -5.2103e-02,  2.7277e-01,  3.6866e-01,\n",
       "                      -5.9522e-01, -2.7680e-01, -3.9342e-01,  2.7482e-01,  1.4294e-02,\n",
       "                      -3.8747e-01, -1.6968e-03, -6.0774e-01,  2.4359e-01, -7.5328e-01,\n",
       "                      -2.4859e-01,  5.1438e-01, -4.3507e-01, -2.7122e-01, -3.1555e-01,\n",
       "                       3.7392e-01, -3.2283e-01,  6.9892e-01, -6.0065e-02, -8.8548e-01,\n",
       "                      -1.2313e+00, -3.3540e-01, -3.8092e-02,  2.7855e-01, -1.8594e-01,\n",
       "                      -2.1347e-01, -7.6705e-01, -3.2844e-01, -2.8271e-01, -1.4810e-02,\n",
       "                       3.3146e-02,  5.9551e-03,  9.8536e-02, -5.1386e-02,  9.6942e-01,\n",
       "                      -8.6849e-02, -5.4735e-01,  6.3671e-01, -7.1395e-01, -2.1338e-01,\n",
       "                      -2.3629e-01,  7.6897e-01, -4.5050e-01,  4.0542e-01, -6.5218e-01,\n",
       "                      -3.5357e-02,  9.0482e-02, -5.9077e-01, -4.9040e-02, -4.3965e-01,\n",
       "                      -1.3701e-01, -2.1294e-01, -2.3281e-01, -5.5936e-01,  3.7871e-01,\n",
       "                       2.6345e-01,  1.4182e-01, -2.0583e-01,  1.3799e-01,  2.5788e-01,\n",
       "                      -1.3850e-01,  4.5257e-01,  2.6723e-01,  8.1334e-01, -1.0773e+00,\n",
       "                      -3.0103e-01], device='cuda:0')),\n",
       "             ('mol_conv2.lin_query.weight',\n",
       "              tensor([[-0.0174, -0.3487, -0.0329,  ...,  0.0739,  0.5195, -1.5932],\n",
       "                      [ 0.1296, -0.6967, -0.0305,  ...,  0.0615, -0.0306, -0.2379],\n",
       "                      [ 0.1884,  0.1288,  0.0257,  ...,  0.0851,  0.2872, -0.4841],\n",
       "                      ...,\n",
       "                      [ 0.2000,  0.1048,  0.0652,  ...,  0.0258, -0.1361,  1.3698],\n",
       "                      [-0.2810,  0.2375,  0.1073,  ..., -0.0805, -0.3155, -1.3543],\n",
       "                      [ 0.1829, -0.5055, -0.0829,  ...,  0.0751,  0.1694, -0.7393]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv2.lin_query.bias',\n",
       "              tensor([-0.2972, -0.1680, -0.2113, -0.2588, -0.3362, -0.0477, -0.2126, -0.0688,\n",
       "                      -0.1919,  0.1914, -0.3909,  0.1653, -0.1050,  0.2282, -0.0131, -0.3311,\n",
       "                      -0.2230,  0.2653,  0.3652,  0.0781,  0.0830,  0.4546, -0.3564,  0.3396,\n",
       "                       0.6104,  0.3996,  0.0847,  0.4836,  0.4418,  0.1016, -0.2527, -0.4835,\n",
       "                      -0.1229, -0.1073,  0.3752, -0.3437,  0.2011,  0.3927,  0.3513,  0.4019,\n",
       "                       0.1174, -0.4482, -0.2354, -0.2918, -0.5765,  0.0799, -0.4870,  0.1689,\n",
       "                       0.0831, -0.2626, -0.4679, -0.3997, -0.3354, -0.3433, -0.1453,  0.3309,\n",
       "                      -0.2306,  0.4968, -0.2965,  0.3444, -0.4416, -0.3678, -0.0708,  0.2635,\n",
       "                      -0.3658, -0.1386, -0.2712, -0.3086, -0.3260, -0.3352, -0.3565, -0.3555,\n",
       "                       0.1853,  0.1919,  0.2799,  0.3893, -0.4097,  0.3117, -0.3239,  0.3624,\n",
       "                       0.3519, -0.3725, -0.3073, -0.1206,  0.5229,  0.2616, -0.2195,  0.3376,\n",
       "                       0.1353,  0.4783, -0.3803, -0.2624, -0.1775,  0.4160, -0.3456, -0.2698,\n",
       "                      -0.0366, -0.2085, -0.3006,  0.3755, -0.6081,  0.3385, -0.3435, -0.2066,\n",
       "                      -0.3314,  0.2511,  0.2854,  0.1011,  0.1204, -0.0591, -0.2109, -0.3621,\n",
       "                      -0.1363, -0.4575,  0.1643, -0.6040,  0.2439, -0.1313,  0.2856, -0.2231,\n",
       "                      -0.3340,  0.2490,  0.3131, -0.4700,  0.1781,  0.3516, -0.2981,  0.0898,\n",
       "                      -0.5268, -0.1130,  0.3935,  0.4196, -0.6262,  0.3286, -0.3340,  0.2637,\n",
       "                       0.5466, -0.4201, -0.2586, -0.3161, -0.2690,  0.2312, -0.2516, -0.0957,\n",
       "                       0.4004,  0.4009,  0.3860, -0.3867,  0.4585, -0.4337, -0.2994,  0.2336,\n",
       "                       0.5629,  0.3862, -0.1195, -0.2106], device='cuda:0')),\n",
       "             ('mol_conv2.lin_value.weight',\n",
       "              tensor([[ 0.2309, -0.2381, -0.0248,  ..., -0.1082,  0.3854,  0.1795],\n",
       "                      [ 0.1342, -0.0554, -0.0838,  ...,  0.0737,  0.5016,  0.1137],\n",
       "                      [ 0.0475, -0.4139,  0.1024,  ..., -0.0186, -0.0417, -0.2867],\n",
       "                      ...,\n",
       "                      [-0.0321,  0.0205,  0.0076,  ..., -0.1020, -0.0457,  0.0575],\n",
       "                      [-0.1597, -0.3834,  0.0662,  ..., -0.1084, -1.0519,  0.2027],\n",
       "                      [-0.0175, -0.0693, -0.0068,  ..., -0.0519, -0.1894, -0.0191]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv2.lin_value.bias',\n",
       "              tensor([-8.1557e-02,  2.6893e-02,  1.0805e-01, -5.8477e-02,  1.2352e-01,\n",
       "                      -4.3884e-02, -8.1996e-02, -6.3229e-02,  5.0702e-02,  7.5006e-02,\n",
       "                      -5.8682e-02, -1.2624e-01, -8.9774e-02, -3.5433e-02,  3.1101e-02,\n",
       "                       9.0553e-03, -1.5782e-01, -6.9827e-02, -4.1264e-02, -7.9967e-02,\n",
       "                       1.8631e-01,  2.0075e-01, -2.6354e-02, -1.4655e-01, -6.9673e-02,\n",
       "                      -8.5570e-02, -1.3963e-01, -1.0564e-01,  1.1083e-01,  6.6515e-02,\n",
       "                       7.3367e-02, -6.9900e-02, -3.4344e-02, -1.2015e-01,  1.1963e-01,\n",
       "                       1.2344e-02, -6.4429e-02, -4.9238e-02,  9.7500e-03, -2.0250e-01,\n",
       "                       1.1562e-01, -8.1354e-02, -1.1951e-01,  1.9877e-01, -1.1647e-01,\n",
       "                      -4.8821e-02, -9.8749e-02,  4.1537e-02, -2.0427e-02,  4.5897e-02,\n",
       "                       2.1412e-02, -6.8112e-05, -1.0198e-01,  1.0759e-02,  1.5181e-01,\n",
       "                      -2.0123e-01,  1.9723e-02, -1.2612e-01,  1.2076e-01, -4.1875e-04,\n",
       "                      -1.0335e-01, -6.2055e-02,  8.3691e-03,  2.6141e-02, -1.9459e-01,\n",
       "                      -2.7344e-03, -7.6540e-02, -8.6190e-02, -1.2134e-01,  1.3293e-01,\n",
       "                       5.9550e-02,  1.4300e-01,  9.0049e-03, -4.9892e-02, -6.2261e-02,\n",
       "                      -1.0176e-01, -2.7137e-02, -7.9581e-02, -4.0610e-02,  4.2493e-02,\n",
       "                      -8.7312e-02, -3.7191e-02,  4.7318e-02,  7.9281e-03, -1.9043e-02,\n",
       "                      -9.3603e-02, -1.3216e-01, -9.9569e-02, -5.0256e-03, -9.9287e-02,\n",
       "                       7.1223e-02, -6.1288e-02,  2.7687e-02, -7.3301e-02, -3.2015e-02,\n",
       "                      -1.6136e-01,  7.7513e-02, -4.9894e-02, -1.2245e-01,  4.2333e-02,\n",
       "                       1.1298e-01, -4.7864e-02,  2.6676e-02, -1.4174e-01, -9.6713e-02,\n",
       "                      -2.4277e-01, -8.5523e-02, -7.5507e-02, -8.7692e-05, -1.2816e-01,\n",
       "                      -6.9128e-02, -6.5355e-02, -5.8584e-02,  8.8526e-02,  1.5948e-02,\n",
       "                      -1.3061e-02, -1.3234e-01, -1.2582e-01,  8.3358e-02,  2.9086e-01,\n",
       "                       1.7383e-02, -3.9076e-02, -3.4708e-02,  9.3656e-02,  6.6666e-02,\n",
       "                       5.8549e-02, -3.1697e-02, -1.3756e-02, -8.9074e-02, -1.0876e-01,\n",
       "                      -5.5647e-01, -6.9329e-02, -6.7168e-02,  1.0020e-01,  7.6853e-02,\n",
       "                      -1.1644e-01,  1.5173e-01, -1.6663e-01, -3.4874e-02,  7.6687e-02,\n",
       "                       1.5228e-01, -1.0697e-01, -2.7391e-02, -4.6251e-02,  1.6519e-02,\n",
       "                       7.7129e-02,  3.1215e-02, -4.1236e-02,  1.9066e-01,  1.0083e-01,\n",
       "                      -1.5315e-01,  7.9396e-02,  9.6572e-02, -1.1739e-01,  1.2496e-01,\n",
       "                      -4.1646e-02], device='cuda:0')),\n",
       "             ('mol_conv2.lin_skip.weight',\n",
       "              tensor([[-0.2614, -0.0107, -0.0945,  ..., -0.0924, -0.4318, -0.4125],\n",
       "                      [-0.4633,  0.4500,  0.0023,  ..., -0.0389, -0.1352, -0.0530],\n",
       "                      [ 0.2569,  0.4493,  0.0439,  ...,  0.0648,  0.4843, -0.1296],\n",
       "                      ...,\n",
       "                      [ 0.0277,  0.0862,  0.0440,  ..., -0.0394, -0.0537, -0.0923],\n",
       "                      [ 0.3178,  0.1324, -0.0578,  ...,  0.0417,  0.4728,  0.2260],\n",
       "                      [-0.0736,  0.0071, -0.0712,  ...,  0.0062, -0.0765, -0.0307]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv2.lin_skip.bias',\n",
       "              tensor([-0.1543,  0.1100, -0.0828,  0.0585,  0.1403, -0.0970,  0.0392, -0.0499,\n",
       "                       0.0606, -0.0253,  0.1164, -0.0304, -0.1462, -0.0376, -0.0345, -0.0303,\n",
       "                      -0.0741, -0.0363, -0.0548, -0.1287,  0.0606,  0.0975, -0.1428,  0.0263,\n",
       "                      -0.0574, -0.0934, -0.0433, -0.0607, -0.0374,  0.0005,  0.1284, -0.0134,\n",
       "                      -0.1119, -0.0303,  0.1058,  0.1246, -0.0666, -0.1366,  0.0729, -0.0922,\n",
       "                      -0.0308, -0.0775,  0.0039,  0.0817, -0.0129, -0.0711,  0.0267,  0.1622,\n",
       "                      -0.0995, -0.0513, -0.0272, -0.1497, -0.0344,  0.0714,  0.0620, -0.0826,\n",
       "                       0.0752, -0.1325,  0.0576,  0.0222, -0.0873, -0.1427, -0.1759, -0.1381,\n",
       "                      -0.1783, -0.1110, -0.2500, -0.1209, -0.1582,  0.0077,  0.0095, -0.0580,\n",
       "                      -0.0168, -0.1825, -0.1775, -0.0625,  0.1258, -0.1435, -0.0445,  0.0783,\n",
       "                      -0.0947, -0.1732,  0.0323, -0.1880,  0.0249, -0.1379, -0.0820, -0.1038,\n",
       "                      -0.1360,  0.0597,  0.0382, -0.1722, -0.1210, -0.0388, -0.0184, -0.0348,\n",
       "                       0.0159,  0.1103, -0.0802,  0.1407,  0.1014, -0.1131, -0.0220, -0.0974,\n",
       "                      -0.1059, -0.1055, -0.1412, -0.1008,  0.0736, -0.0692,  0.0393, -0.1117,\n",
       "                      -0.0605,  0.0709, -0.1236, -0.0723, -0.0899, -0.0719,  0.0877,  0.1755,\n",
       "                      -0.1230, -0.1571, -0.1188,  0.0986,  0.1512,  0.0833, -0.1373,  0.0690,\n",
       "                      -0.0345, -0.0093, -0.4476, -0.0016,  0.0504, -0.0678,  0.1017,  0.0066,\n",
       "                       0.0294,  0.0286,  0.0007,  0.0032,  0.0733,  0.0634, -0.2161, -0.1002,\n",
       "                      -0.1649,  0.0074,  0.2401, -0.1568,  0.1999,  0.0826, -0.1088, -0.0519,\n",
       "                       0.0290, -0.0420,  0.1706, -0.0179], device='cuda:0')),\n",
       "             ('mol_conv3.lin_key.weight',\n",
       "              tensor([[-0.0504, -0.3305, -0.1558,  ..., -0.0790,  0.9134, -0.0482],\n",
       "                      [ 0.5495, -0.5519, -0.2368,  ..., -0.0164, -0.4267, -0.0352],\n",
       "                      [-0.1461, -0.4177, -0.2193,  ...,  0.0103,  0.6078, -0.0455],\n",
       "                      ...,\n",
       "                      [-0.3277, -0.0483, -0.2325,  ..., -0.0165,  0.2613,  0.0271],\n",
       "                      [ 0.2918,  0.1395,  0.3655,  ...,  0.0241, -0.5685,  0.0454],\n",
       "                      [-0.6688, -0.1048, -0.1657,  ...,  0.0107,  0.5601, -0.0154]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv3.lin_key.bias',\n",
       "              tensor([ 6.0279e-01, -9.9388e-02,  3.4830e-01, -6.8861e-02,  4.3461e-02,\n",
       "                      -7.3533e-02,  4.0395e-01, -5.1239e-02, -1.1865e-01, -1.3236e-01,\n",
       "                      -2.7873e-01,  5.3696e-01, -4.7840e-01, -4.2311e-02, -4.4582e-01,\n",
       "                      -5.0408e-01, -1.5384e-01,  2.8143e-01,  6.1916e-01, -2.6907e-01,\n",
       "                      -2.3729e-01, -3.4240e-01, -6.9110e-01, -7.6707e-02,  3.6894e-01,\n",
       "                      -2.2307e-01,  2.7597e-01,  2.9653e-01, -1.9615e-01, -4.9539e-01,\n",
       "                       4.2840e-02,  2.8412e-02,  3.9611e-01,  7.9373e-01, -1.0806e-01,\n",
       "                       5.1935e-01,  3.1866e-01,  2.4359e-01,  4.2534e-01,  2.9970e-01,\n",
       "                      -1.9950e-02,  4.8958e-01, -1.3864e-01, -3.6437e-01, -6.0147e-01,\n",
       "                      -3.7807e-01,  1.7117e-02,  6.9891e-02,  5.9956e-02, -2.8226e-01,\n",
       "                      -3.9810e-01,  5.3936e-01, -3.1956e-01, -4.0444e-01, -8.7121e-02,\n",
       "                       1.5476e-01, -1.0391e-01, -3.8174e-01,  8.0970e-01,  6.0706e-02,\n",
       "                       2.6446e-01, -6.5673e-01, -2.0637e-01,  4.5221e-01, -4.5674e-01,\n",
       "                      -2.3966e-01, -3.3186e-01, -3.9234e-01, -4.6317e-01,  5.6678e-01,\n",
       "                      -3.0281e-01, -2.6422e-01, -3.0177e-01,  5.1420e-01,  1.8663e-01,\n",
       "                      -3.5187e-01, -2.0206e-01,  2.7997e-01,  6.3237e-03,  9.2420e-02,\n",
       "                       3.3077e-01,  5.1707e-02,  2.9808e-01, -4.3119e-01, -9.1411e-02,\n",
       "                       2.1240e-01,  4.5801e-02, -8.9618e-02,  3.4818e-01, -4.2143e-01,\n",
       "                      -3.5062e-01, -1.3188e-01, -3.1719e-01, -3.8834e-01, -4.7231e-01,\n",
       "                      -4.4598e-01,  6.9319e-01, -3.0133e-01,  8.6683e-02, -6.9074e-01,\n",
       "                       5.2800e-01, -1.7508e-01,  6.8743e-01,  5.6293e-02,  4.8039e-01,\n",
       "                      -8.6786e-01, -4.0690e-01,  1.0956e-01, -1.8599e-01,  4.6385e-01,\n",
       "                       6.1814e-01, -8.1914e-02,  4.5097e-01,  5.1238e-01,  9.6318e-02,\n",
       "                      -3.7404e-02,  2.9969e-01,  5.4816e-01,  9.6824e-01, -4.3272e-01,\n",
       "                      -1.4185e-01,  2.8306e-01, -7.5918e-01,  1.2078e-01,  3.4543e-01,\n",
       "                       4.3715e-01,  1.4345e-01, -3.4642e-02,  6.5585e-01,  3.9776e-01,\n",
       "                      -5.1272e-01, -1.9627e-01, -2.4224e-01, -8.3221e-01,  4.7544e-01,\n",
       "                       3.6844e-01, -5.1584e-01, -7.7639e-01, -5.6608e-01, -2.6498e-01,\n",
       "                      -2.1765e-01,  1.1295e-01, -5.6693e-01, -1.5091e-01, -9.9912e-02,\n",
       "                       1.0082e-01,  6.0884e-02,  4.3675e-01,  5.1056e-01, -1.1971e-02,\n",
       "                       4.4491e-02, -3.7605e-01,  5.8470e-01,  5.8160e-01,  2.5254e-01,\n",
       "                      -1.4728e-01, -8.0045e-01, -1.4838e-01, -6.1407e-02,  4.5509e-01,\n",
       "                      -6.6765e-02,  4.2857e-01,  7.5985e-01, -3.5256e-01,  6.8312e-01,\n",
       "                      -3.4179e-02,  1.0070e-02, -3.2686e-01,  2.5245e-01, -1.5289e-01,\n",
       "                      -3.0248e-01,  1.1740e-01,  3.5259e-02, -3.4388e-01, -9.8014e-01,\n",
       "                       4.1352e-01, -2.7175e-01,  2.5256e-01, -1.5265e-01, -2.3784e-01,\n",
       "                      -5.8058e-02,  3.5401e-02, -7.8166e-01,  3.4573e-01, -3.8199e-01,\n",
       "                       4.9279e-01, -8.4078e-01,  1.0570e-01, -1.9289e-02,  8.1683e-02,\n",
       "                       9.3924e-01, -1.1568e-01,  1.7721e-01,  7.3335e-01,  1.1017e-01,\n",
       "                      -2.3957e-01,  7.6982e-01, -9.1308e-02, -5.7593e-01, -5.9675e-01,\n",
       "                       5.7422e-01,  2.6903e-01,  4.6555e-01, -6.3732e-02,  7.8444e-01,\n",
       "                       5.0025e-01, -4.4856e-01, -1.8600e-01,  1.5881e-01, -7.4842e-01,\n",
       "                       4.1402e-01,  5.4987e-01, -1.4890e-01,  5.3694e-01,  4.0699e-01,\n",
       "                      -3.2805e-02, -4.5307e-01, -1.2324e-01,  1.3519e-02, -1.5616e-01,\n",
       "                       3.6440e-01, -7.3176e-01,  2.4399e-01,  1.7731e-01, -4.6130e-01,\n",
       "                       6.7665e-01,  5.0109e-01, -6.5706e-02,  5.2313e-01,  2.8965e-01,\n",
       "                      -1.4622e-01, -9.8118e-04, -2.3721e-01, -6.6827e-02,  5.5837e-02,\n",
       "                      -1.1440e-01,  4.1554e-02, -1.2571e+00, -3.7267e-01, -3.9817e-01,\n",
       "                      -4.8290e-01,  2.3620e-01,  8.9847e-02, -2.4921e-01,  4.4653e-01,\n",
       "                      -4.3449e-01,  2.1016e-02,  6.2469e-01,  5.6680e-01,  3.7641e-01,\n",
       "                       7.7875e-01,  1.4528e-01, -4.0228e-01,  2.8342e-01, -4.3186e-01,\n",
       "                      -3.6325e-01, -3.5378e-01, -2.2551e-01, -4.1040e-01, -7.1179e-03,\n",
       "                       6.0367e-01, -6.0334e-01, -2.0154e-01,  1.4279e-01,  3.0648e-01,\n",
       "                      -8.0009e-01, -2.0379e-01, -1.3894e-01, -7.6145e-01,  2.6359e-01,\n",
       "                      -1.0032e-02, -1.5931e-01,  5.1074e-01, -1.2433e-01, -3.6511e-01,\n",
       "                      -3.8398e-01, -2.5540e-01,  2.9288e-01, -6.9528e-01, -3.1422e-02,\n",
       "                       1.5393e-01, -1.2445e-02, -2.6993e-01,  2.9115e-01,  4.0288e-01,\n",
       "                      -1.0907e-03, -8.5673e-01, -1.8705e-01, -2.8296e-01,  5.5883e-02,\n",
       "                       3.7252e-01, -2.1572e-01, -8.7421e-01, -3.0252e-01, -1.2041e-01,\n",
       "                      -4.7524e-01,  7.1817e-02, -1.4754e-02, -3.9565e-01,  2.3812e-01,\n",
       "                       3.1554e-01, -4.4267e-01,  6.8897e-02, -3.5974e-01, -9.6885e-02,\n",
       "                      -1.4232e-01,  4.5096e-01,  2.5800e-01, -3.4780e-01,  4.9396e-01,\n",
       "                      -1.0243e-01, -1.1790e-02], device='cuda:0')),\n",
       "             ('mol_conv3.lin_query.weight',\n",
       "              tensor([[-5.4076e-01, -3.3129e-01,  4.3388e-01,  ..., -1.3871e-02,\n",
       "                       -3.0592e-01,  4.1637e-02],\n",
       "                      [ 9.5820e-02,  6.3279e-02, -1.1233e-01,  ..., -2.7467e-02,\n",
       "                       -5.7315e-02, -4.6893e-02],\n",
       "                      [-1.4060e-01, -5.8076e-01,  3.1082e-01,  ...,  9.7791e-03,\n",
       "                       -4.1013e-01,  1.9470e-02],\n",
       "                      ...,\n",
       "                      [ 2.5338e-01, -8.1223e-01,  4.6308e-02,  ...,  1.8414e-04,\n",
       "                       -1.5084e-01,  2.2503e-02],\n",
       "                      [ 4.3481e-01,  5.9708e-01, -2.4119e-01,  ...,  6.2623e-02,\n",
       "                        4.2114e-01,  2.8676e-02],\n",
       "                      [ 4.9974e-03, -6.2464e-01,  3.7453e-01,  ..., -4.7242e-03,\n",
       "                       -7.9245e-01, -1.7005e-02]], device='cuda:0')),\n",
       "             ('mol_conv3.lin_query.bias',\n",
       "              tensor([-0.0885, -0.1845, -0.3847,  0.1989, -0.2074,  0.3324, -0.1506, -0.0069,\n",
       "                       0.1816, -0.2459, -0.0473, -0.0262, -0.0263, -0.5179, -0.3315,  0.2467,\n",
       "                      -0.0495,  0.1393,  0.0671,  0.3200,  0.1101,  0.2484, -0.0841, -0.1893,\n",
       "                      -0.2117,  0.1503, -0.2372, -0.1085,  0.1971,  0.2226, -0.1155, -0.1260,\n",
       "                       0.0882, -0.1479,  0.0771, -0.1485, -0.1180, -0.0504,  0.1032,  0.1926,\n",
       "                       0.1006, -0.2586,  0.1391,  0.0594,  0.1315,  0.2186,  0.2636,  0.0635,\n",
       "                      -0.2056, -0.2867, -0.1938,  0.0764,  0.0239, -0.0429, -0.0523, -0.4981,\n",
       "                       0.0064,  0.3112, -0.0728,  0.1091,  0.0800,  0.3229,  0.0303, -0.1707,\n",
       "                      -0.1196, -0.3618,  0.1862,  0.2313,  0.1653, -0.3356, -0.0543, -0.1787,\n",
       "                       0.5360, -0.2847,  0.2487,  0.1019,  0.1450, -0.1482,  0.0757,  0.2483,\n",
       "                      -0.3261,  0.1518, -0.1623,  0.2611,  0.1099, -0.4259, -0.2665,  0.2758,\n",
       "                      -0.4299,  0.4776,  0.1724,  0.0521,  0.0602,  0.1936,  0.0274,  0.2661,\n",
       "                      -0.3279,  0.1682, -0.0736,  0.0685,  0.2231, -0.0609, -0.3190, -0.1457,\n",
       "                       0.1366,  0.0405,  0.5161,  0.0599,  0.3166, -0.0898, -0.1224,  0.5070,\n",
       "                      -0.3043,  0.1502,  0.3364,  0.3110,  0.0408, -0.2803, -0.1155,  0.2868,\n",
       "                       0.0090,  0.4029,  0.2999, -0.0545, -0.0765, -0.1723,  0.4363, -0.1216,\n",
       "                       0.0982, -0.2407,  0.1802, -0.0040, -0.1304,  0.0053, -0.2105, -0.2122,\n",
       "                       0.0958,  0.0540,  0.1301,  0.2231,  0.0077, -0.4513,  0.0082,  0.0556,\n",
       "                       0.2368,  0.1764,  0.3960,  0.0267,  0.3410, -0.0425,  0.2421,  0.3064,\n",
       "                       0.0292, -0.1058, -0.0325,  0.0388,  0.0532,  0.2167, -0.2308, -0.4823,\n",
       "                       0.1945, -0.7432, -0.0815, -0.4134, -0.2735, -0.0759,  0.1957, -0.1780,\n",
       "                      -0.2992,  0.3646,  0.0485,  0.3383, -0.1565,  0.1585,  0.1157, -0.4541,\n",
       "                       0.3367,  0.1316,  0.2913,  0.2215, -0.1348, -0.2008,  0.1010, -0.2168,\n",
       "                      -0.0836,  0.0238,  0.3527, -0.1375, -0.1930, -0.2595, -0.1478, -0.0248,\n",
       "                      -0.2861, -0.4049, -0.3479, -0.3683,  0.0259,  0.2137, -0.0805,  0.1235,\n",
       "                      -0.0566,  0.1283, -0.1061, -0.2609, -0.2135,  0.3568,  0.3789,  0.1140,\n",
       "                       0.2894, -0.1101, -0.4407, -0.6358,  0.3056, -0.1598, -0.0767, -0.1802,\n",
       "                       0.0875,  0.0607,  0.0743,  0.2332, -0.2636, -0.0574, -0.2374,  0.1825,\n",
       "                       0.3296,  0.0316,  0.0270, -0.1212, -0.1342,  0.2792,  0.0353,  0.0990,\n",
       "                       0.4329,  0.0396, -0.2717,  0.1576, -0.1520,  0.5959,  0.3344, -0.1596,\n",
       "                       0.4378, -0.4477, -0.2460,  0.0012, -0.0419, -0.2510, -0.3459, -0.3738,\n",
       "                      -0.3865, -0.4614, -0.2212,  0.2806,  0.4307,  0.3515, -0.1676, -0.0222,\n",
       "                      -0.0375,  0.0062,  0.0702,  0.5947, -0.4478,  0.2589,  0.3435, -0.1078,\n",
       "                       0.0045,  0.0865, -0.0100, -0.2039,  0.0924, -0.0593, -0.0992,  0.3199,\n",
       "                      -0.3001,  0.2277,  0.1833,  0.0438,  0.3506, -0.3708,  0.2712,  0.0142,\n",
       "                      -0.1982,  0.2435,  0.2007, -0.2193,  0.2141,  0.0596,  0.4475, -0.3308,\n",
       "                       0.0154,  0.0190,  0.0169,  0.0616,  0.4221,  0.1971,  0.5155,  0.0380,\n",
       "                      -0.1172,  0.0536, -0.0446, -0.3226, -0.3998, -0.2494, -0.6083,  0.5075,\n",
       "                       0.1127,  0.2414, -0.1498, -0.0833, -0.1688, -0.2749,  0.1865, -0.7609],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv3.lin_value.weight',\n",
       "              tensor([[ 0.0744, -0.1178, -0.0275,  ..., -0.0582, -0.1143,  0.0551],\n",
       "                      [ 0.0799, -0.0016, -0.0628,  ...,  0.0726, -0.4904,  0.0404],\n",
       "                      [-0.0016,  0.0532, -0.0134,  ..., -0.0521, -0.0307, -0.0695],\n",
       "                      ...,\n",
       "                      [-0.6618,  0.2730,  0.3226,  ..., -0.0234, -0.9939,  0.0061],\n",
       "                      [ 0.0375,  0.2314, -0.3280,  ..., -0.0323, -0.4194, -0.0158],\n",
       "                      [-0.0916, -0.0692,  0.0228,  ...,  0.0603, -0.0191,  0.0201]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv3.lin_value.bias',\n",
       "              tensor([-0.1249, -0.0063, -0.0435, -0.1557, -0.1438, -0.1897, -0.1384, -0.1083,\n",
       "                      -0.0676, -0.0431, -0.1374, -0.0587, -0.3094, -0.1203, -0.0522, -0.1043,\n",
       "                       0.0072, -0.1135, -0.1372, -0.1319, -0.0457, -0.0451, -0.0993, -0.1131,\n",
       "                      -0.4562, -0.1114,  0.0617, -0.0369, -0.3136, -0.0934, -0.0946, -0.2545,\n",
       "                      -0.1222, -0.1294, -0.0497, -0.1093,  0.0218,  0.0164, -0.1131, -0.0617,\n",
       "                      -0.2041,  0.0212, -0.0820, -0.0150, -0.0458, -0.1104, -0.1167, -0.0365,\n",
       "                      -0.1092, -0.2336, -0.1025, -0.1065, -0.0135, -0.0250, -0.1128, -0.0848,\n",
       "                      -0.0184, -0.0641,  0.0242, -0.0497,  0.0393, -0.1090, -0.0380, -0.1599,\n",
       "                      -0.1194, -0.1563, -0.1021, -0.1056, -0.0784, -0.1342, -0.0598, -0.1377,\n",
       "                      -0.1613, -0.1017, -0.2693, -0.2455, -0.0618, -0.0455, -0.1299, -0.0830,\n",
       "                      -0.1423, -0.1688, -0.1209, -0.0893, -0.1228, -0.0234, -0.0895, -0.1526,\n",
       "                      -0.1015, -0.1389, -0.0464, -0.0818, -0.1191, -0.0459,  0.1076, -0.0463,\n",
       "                      -0.1091,  0.2445,  0.0016, -0.0616, -0.1551, -0.0393, -0.0573, -0.0441,\n",
       "                      -0.0871, -0.1023,  0.0546, -0.0215, -0.0422, -0.1326, -0.2402, -0.0397,\n",
       "                      -0.0045, -0.0983, -0.0992, -0.0946, -0.0597, -0.0718, -0.0074, -0.0988,\n",
       "                      -0.0978, -0.1268, -0.1313, -0.0727, -0.0543, -0.0673, -0.0847, -0.1268,\n",
       "                      -0.0682, -0.0875, -0.1467, -0.0941, -0.1223, -0.1015, -0.0818, -0.0830,\n",
       "                      -0.1938, -0.1084, -0.1512, -0.1469, -0.0199, -0.0981,  0.1606, -0.0792,\n",
       "                       0.0754, -0.0634, -0.0208,  0.0960, -0.1255, -0.1163, -0.0283, -0.0146,\n",
       "                      -0.0993, -0.1720, -0.0720,  0.0526, -0.0832, -0.0108, -0.0561, -0.0428,\n",
       "                      -0.0735, -0.1371, -0.0507, -0.2052, -0.1337, -0.0854, -0.0967, -0.0945,\n",
       "                      -0.1226, -0.0235, -0.0075, -0.1353, -0.1228, -0.0028, -0.3133, -0.1005,\n",
       "                      -0.0566, -0.1414, -0.0861, -0.0306, -0.0598, -0.0605, -0.1437, -0.0421,\n",
       "                      -0.0340, -0.0457,  0.1345, -0.1314, -0.1117, -0.0269, -0.0750, -0.2423,\n",
       "                      -0.1020, -0.1192, -0.1253, -0.1235, -0.0783, -0.1935, -0.0729, -0.3312,\n",
       "                      -0.0201, -0.0937, -0.0793, -0.1489, -0.0914,  0.1151, -0.1039,  0.0216,\n",
       "                      -0.0692, -0.0841, -0.1850, -0.0507, -0.1293, -0.1079, -0.1630, -0.3572,\n",
       "                      -0.0341, -0.1063, -0.0896, -0.1345, -0.0954, -0.0064,  0.0809, -0.0625,\n",
       "                       0.1221, -0.0664,  0.1785, -0.2137, -0.2280, -0.1159, -0.0975,  0.0394,\n",
       "                       0.1093, -0.0391, -0.1896, -0.0813, -0.0680, -0.0647, -0.2081, -0.0352,\n",
       "                      -0.0368, -0.1198, -0.0723, -0.1043, -0.0862, -0.0261, -0.0751, -0.0303,\n",
       "                      -0.0275, -0.0458, -0.0027, -0.0022, -0.1469, -0.1203,  0.0265, -0.2539,\n",
       "                      -0.1025, -0.1268, -0.0945, -0.1043, -0.1555, -0.0491, -0.0725, -0.1307,\n",
       "                      -0.0537, -0.0848, -0.0478, -0.2242, -0.1483, -0.1362, -0.1010, -0.0382,\n",
       "                      -0.0865, -0.0157, -0.3251,  0.0722, -0.1594, -0.0657, -0.0849, -0.1038,\n",
       "                      -0.0357, -0.0055,  0.0061, -0.0899, -0.0771, -0.1015, -0.2877, -0.1012,\n",
       "                      -0.0281, -0.0515, -0.3442, -0.1007, -0.0771, -0.1359,  0.0936, -0.0319,\n",
       "                      -0.0842, -0.0067, -0.1447,  0.0415, -0.0665, -0.1054, -0.0210, -0.2567,\n",
       "                      -0.3948, -0.0744, -0.0518,  0.1322, -0.0053, -0.0641, -0.0799, -0.1067],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_conv3.lin_skip.weight',\n",
       "              tensor([[-5.9543e-02, -9.9128e-03,  4.1268e-02,  ...,  1.3912e-02,\n",
       "                       -1.3380e-01,  1.4795e-02],\n",
       "                      [-1.2887e+00, -1.0146e+00, -5.5757e-01,  ..., -6.1107e-02,\n",
       "                        1.4715e-01, -1.2482e-03],\n",
       "                      [-2.0273e-02, -8.7500e-02, -1.3896e-02,  ...,  1.1416e-02,\n",
       "                       -1.6988e-03,  4.3005e-02],\n",
       "                      ...,\n",
       "                      [-1.4704e+00,  9.1019e-02, -3.6003e-01,  ...,  1.2399e-02,\n",
       "                        4.6511e-01,  4.3980e-02],\n",
       "                      [ 1.7261e-01,  4.3165e-01, -2.3264e-01,  ..., -1.0155e-02,\n",
       "                       -4.2267e-01, -7.4347e-02],\n",
       "                      [ 4.2517e-02, -4.6469e-02,  5.2069e-02,  ...,  9.6057e-03,\n",
       "                       -2.1135e-02,  3.6853e-02]], device='cuda:0')),\n",
       "             ('mol_conv3.lin_skip.bias',\n",
       "              tensor([-1.2117e-01,  3.9313e-02, -1.0789e-01, -1.6608e-01, -2.1419e-01,\n",
       "                      -1.6158e-01, -1.3465e-01, -8.9596e-02, -1.3322e-01, -7.8800e-02,\n",
       "                      -9.0884e-02, -6.4228e-02, -2.3107e-01, -4.6483e-02, -1.2640e-02,\n",
       "                      -9.9379e-02,  1.2282e-02, -1.3156e-01, -1.4585e-01, -6.5621e-02,\n",
       "                      -2.2737e-02, -8.6221e-02, -5.2511e-02, -3.6336e-02, -5.9876e-01,\n",
       "                      -1.1147e-01,  6.7819e-02,  5.6620e-02, -3.4530e-01, -9.6015e-02,\n",
       "                      -1.3043e-01, -2.7702e-01, -6.5162e-02, -1.9106e-01, -1.3870e-01,\n",
       "                      -1.6905e-01, -1.2039e-01, -7.0964e-02,  2.7329e-02, -1.3443e-01,\n",
       "                      -9.0183e-02,  5.3766e-02, -1.4735e-01, -1.5308e-01, -1.5463e-01,\n",
       "                      -1.2511e-01, -1.7256e-01, -6.8955e-02, -8.5199e-02, -1.6922e-01,\n",
       "                      -6.5307e-02, -1.9291e-03, -3.7505e-02, -1.5773e-02, -1.3526e-01,\n",
       "                      -1.0846e-01, -1.2174e-01, -7.1805e-02, -1.2245e-02, -8.6378e-02,\n",
       "                       1.1128e-01, -9.1021e-03, -1.0805e-01, -1.4484e-01, -1.1016e-01,\n",
       "                      -1.1548e-01, -1.8888e-02, -1.2481e-01, -9.8988e-02, -7.4334e-02,\n",
       "                      -8.4155e-02, -4.1771e-02, -1.4587e-01, -1.7241e-01, -2.2835e-01,\n",
       "                      -2.7886e-01, -1.7321e-02, -8.5628e-02, -1.6062e-01, -1.1316e-02,\n",
       "                      -2.5205e-02, -1.9858e-01, -1.0547e-01, -1.3019e-01, -6.1469e-02,\n",
       "                      -7.5329e-02, -7.9988e-02, -9.5740e-02, -6.9103e-02, -2.8741e-02,\n",
       "                      -1.3866e-01, -3.5412e-02, -9.9509e-02, -8.1302e-03,  1.8042e-01,\n",
       "                      -2.0994e-02, -3.6629e-02,  1.8784e-01,  8.2369e-02, -3.1475e-02,\n",
       "                      -2.3237e-01, -9.5974e-02, -5.2650e-02, -1.3843e-01, -5.2720e-02,\n",
       "                      -1.0453e-01,  5.0597e-03,  3.6998e-04, -1.4178e-01, -1.5275e-01,\n",
       "                      -1.5130e-01, -7.5733e-02, -1.1281e-01, -6.3255e-02, -1.7952e-01,\n",
       "                      -8.9116e-02, -4.5159e-02, -1.0770e-01, -4.6444e-02, -2.4077e-02,\n",
       "                      -5.4536e-02, -5.7102e-02, -8.4655e-02, -1.2477e-01, -6.6789e-02,\n",
       "                      -1.1423e-01, -1.2179e-01, -2.4063e-02, -1.2515e-01, -1.2093e-01,\n",
       "                      -6.2262e-02,  2.0976e-02, -1.2090e-01,  1.3034e-02, -1.1724e-01,\n",
       "                      -6.6655e-02, -2.1434e-01, -1.1887e-01, -1.7532e-01, -2.9651e-02,\n",
       "                       1.0882e-02, -4.3954e-02,  1.0215e-01,  2.6451e-02,  5.6266e-02,\n",
       "                      -1.6812e-01, -1.4005e-03,  2.0924e-02, -1.9699e-02, -1.1487e-01,\n",
       "                      -1.1098e-01, -1.3612e-01, -1.1587e-01, -1.3394e-01,  7.0171e-03,\n",
       "                       1.0596e-01, -7.2813e-02, -1.0548e-01, -1.3321e-01, -5.9424e-02,\n",
       "                      -1.0512e-01, -4.5013e-02, -7.4703e-02, -1.4509e-01, -4.5072e-02,\n",
       "                      -7.6049e-02, -2.3900e-02, -6.1770e-02, -1.4671e-02, -1.1570e-01,\n",
       "                       1.2625e-01, -3.2802e-03, -1.8112e-01, -6.0280e-02, -4.6640e-01,\n",
       "                      -9.1877e-02, -1.4450e-01, -1.7174e-02, -1.1084e-01, -9.1859e-02,\n",
       "                      -1.4887e-01, -1.5993e-01, -6.3502e-02,  1.8536e-02, -1.6990e-02,\n",
       "                      -1.1952e-01,  1.4970e-01, -1.4709e-01, -2.3102e-02,  9.4763e-02,\n",
       "                      -1.6475e-02, -3.2209e-01, -5.8058e-03, -6.2430e-02, -1.5296e-02,\n",
       "                      -1.1795e-01,  3.5060e-02, -9.0767e-02, -2.4804e-02, -2.4080e-01,\n",
       "                      -1.3893e-01, -5.9959e-02, -1.6874e-01, -7.9111e-02, -7.7258e-02,\n",
       "                       1.8743e-01, -3.3008e-02, -1.1915e-01,  4.0951e-03,  2.0948e-03,\n",
       "                      -1.1722e-01, -7.7501e-02, -4.1998e-02, -7.4143e-02, -6.9801e-02,\n",
       "                      -3.4088e-01, -1.2726e-01, -6.5565e-02, -3.0713e-02, -7.3319e-02,\n",
       "                      -1.3902e-01, -1.1842e-01,  6.7306e-02, -1.4825e-01,  1.2436e-01,\n",
       "                       1.1431e-02,  2.3041e-01, -2.4834e-01, -1.5749e-01, -9.6170e-02,\n",
       "                      -9.3390e-02, -6.3790e-02,  6.8418e-02, -1.3342e-01, -3.0814e-01,\n",
       "                      -2.3333e-02, -4.8894e-02, -9.0368e-02, -2.0811e-01, -1.0301e-02,\n",
       "                      -1.4292e-01, -1.2470e-01, -5.1005e-02, -9.4593e-02, -2.9020e-02,\n",
       "                      -9.4137e-02, -1.2870e-01, -2.2688e-02, -2.9909e-02, -4.6026e-02,\n",
       "                      -1.2082e-02, -1.5425e-01, -9.1526e-02, -7.8604e-02,  2.8575e-03,\n",
       "                      -2.1743e-01, -2.4933e-02, -1.7434e-01, -1.2095e-01, -2.6413e-02,\n",
       "                      -2.0051e-01, -5.3963e-02,  9.2095e-04,  1.2048e-02, -1.0504e-01,\n",
       "                      -5.6618e-02, -4.5198e-02, -3.3472e-01, -1.6635e-01, -8.6010e-02,\n",
       "                      -6.7088e-02, -1.1707e-01, -1.2035e-01, -6.3726e-02, -2.3387e-01,\n",
       "                       3.4864e-02, -3.8936e-02, -8.1850e-02, -1.0803e-01,  8.8988e-03,\n",
       "                      -6.4678e-02, -5.0200e-02,  8.4510e-02, -1.3709e-01, -4.9583e-02,\n",
       "                      -1.5656e-02, -1.5174e-01, -7.0049e-02,  1.3956e-03, -3.7087e-02,\n",
       "                      -2.8972e-01, -7.0186e-02, -1.3209e-01, -1.4194e-01,  9.7508e-02,\n",
       "                      -1.5758e-01, -7.8715e-02, -7.0910e-02, -1.2841e-01, -7.8923e-02,\n",
       "                      -6.9429e-02, -4.2807e-02, -1.3878e-01, -1.6581e-01, -4.2007e-01,\n",
       "                      -8.3337e-02, -9.7040e-02,  1.3901e-01, -9.5160e-03, -3.6959e-02,\n",
       "                      -1.2548e-01, -1.5133e-01], device='cuda:0')),\n",
       "             ('mol_fc_g1.weight',\n",
       "              tensor([[-7.3316e-03, -9.3235e-02, -2.7068e-02,  ...,  8.9172e-03,\n",
       "                        1.1727e-02, -5.1611e-03],\n",
       "                      [ 1.5079e-02, -1.2095e+00, -1.2414e-02,  ...,  5.7197e-02,\n",
       "                       -2.7331e-01, -3.1359e-02],\n",
       "                      [ 6.6047e-04,  2.1127e-01,  2.5058e-02,  ...,  2.9178e-01,\n",
       "                       -5.7018e-02, -9.0835e-03],\n",
       "                      ...,\n",
       "                      [ 2.3872e-02, -2.7736e-01, -8.9639e-02,  ...,  5.2666e-01,\n",
       "                       -4.7590e-01, -5.3243e-02],\n",
       "                      [-4.0825e-02,  1.9103e-02,  1.9791e-02,  ..., -2.0564e-02,\n",
       "                       -7.9692e-02, -5.5639e-02],\n",
       "                      [-6.7463e-02,  4.0744e-03, -6.6400e-02,  ..., -4.7280e-03,\n",
       "                       -6.2621e-02, -2.7801e-02]], device='cuda:0')),\n",
       "             ('mol_fc_g1.bias',\n",
       "              tensor([-0.1198, -0.2253,  0.0312,  ...,  0.0283, -0.0981, -0.0601],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_fc_g2.weight',\n",
       "              tensor([[-0.0465, -0.2546,  0.3458,  ...,  0.0892, -0.0400,  0.0280],\n",
       "                      [-0.1151,  0.1226,  0.2488,  ...,  0.0162,  0.0546,  0.0499],\n",
       "                      [-0.0867,  0.1876, -0.2365,  ...,  0.0917,  0.0012, -0.0976],\n",
       "                      ...,\n",
       "                      [ 0.0219,  0.0626, -0.4907,  ..., -0.0691,  0.0379,  0.0350],\n",
       "                      [ 0.0408, -0.1502, -0.8004,  ..., -0.0921, -0.0399, -0.0152],\n",
       "                      [ 0.1034, -0.2315, -0.6638,  ...,  0.0089,  0.0755,  0.0212]],\n",
       "                     device='cuda:0')),\n",
       "             ('mol_fc_g2.bias',\n",
       "              tensor([-0.0404, -0.0014,  0.0857, -0.0307,  0.0541,  0.0003, -0.0597,  0.0561,\n",
       "                       0.0011, -0.0709, -0.0181,  0.0205,  0.0663, -0.0586, -0.0592, -0.0437,\n",
       "                      -0.0552, -0.0340,  0.0858, -0.0296, -0.0303,  0.0045,  0.0491, -0.0194,\n",
       "                      -0.0003, -0.0558,  0.0106,  0.0265, -0.0927, -0.0972,  0.0192,  0.0408,\n",
       "                       0.0530, -0.0578, -0.0907,  0.0948,  0.1018, -0.0484, -0.0344, -0.0501,\n",
       "                      -0.0562, -0.0490, -0.0787,  0.0949,  0.0765, -0.0570, -0.0411,  0.0351,\n",
       "                       0.0204,  0.0155, -0.0074, -0.0626,  0.0752, -0.0079, -0.0833, -0.0685,\n",
       "                      -0.0379,  0.0865, -0.1029, -0.1101, -0.0649, -0.0446, -0.0362,  0.0004,\n",
       "                      -0.0442,  0.1435,  0.0052,  0.0400,  0.0698,  0.1125, -0.0400, -0.0388,\n",
       "                      -0.0480,  0.0525, -0.0718, -0.0164, -0.0376,  0.0483,  0.0795,  0.0513,\n",
       "                       0.0732, -0.0601,  0.0290,  0.0621, -0.0356, -0.0576, -0.0645,  0.0673,\n",
       "                       0.0971, -0.0078, -0.0242,  0.0190,  0.0914, -0.0683, -0.0886, -0.0508,\n",
       "                      -0.0721,  0.0404,  0.0522,  0.0014,  0.0511,  0.0602,  0.0449, -0.1162,\n",
       "                      -0.0437, -0.0497,  0.0515,  0.0037,  0.0098,  0.0156, -0.0030, -0.0024,\n",
       "                      -0.0598, -0.0604, -0.0538,  0.0315, -0.0565, -0.0090,  0.0400, -0.0352,\n",
       "                      -0.0108,  0.0823,  0.0287, -0.0591,  0.0115, -0.0406,  0.0783, -0.0003],\n",
       "                     device='cuda:0')),\n",
       "             ('pro_fc_g1.weight',\n",
       "              tensor([[-0.1323, -0.0694, -0.1312,  ..., -0.0823, -0.0731,  0.0624],\n",
       "                      [ 0.0656,  0.0695, -0.0901,  ..., -0.0659,  0.0584, -0.1212],\n",
       "                      [-0.1160, -0.0487, -0.0455,  ..., -0.0460, -0.1311,  0.0159],\n",
       "                      ...,\n",
       "                      [ 0.0154,  0.0910, -0.1258,  ..., -0.0480, -0.0162, -0.0899],\n",
       "                      [-0.1176, -0.0060,  0.1267,  ...,  0.0579, -0.0982,  0.1306],\n",
       "                      [ 0.1270, -0.0602, -0.0869,  ...,  0.0657,  0.0722, -0.0596]],\n",
       "                     device='cuda:0')),\n",
       "             ('pro_fc_g1.bias',\n",
       "              tensor([ 0.0537,  0.0248, -0.0058,  ...,  0.1192, -0.1016,  0.0998],\n",
       "                     device='cuda:0')),\n",
       "             ('pro_fc_g2.weight',\n",
       "              tensor([[ 0.0063,  0.0172, -0.0178,  ...,  0.0092,  0.0244, -0.0273],\n",
       "                      [ 0.0238, -0.0283, -0.0168,  ..., -0.0077,  0.0051,  0.0253],\n",
       "                      [-0.0109, -0.0230, -0.0090,  ...,  0.0308, -0.0058, -0.0246],\n",
       "                      ...,\n",
       "                      [-0.0126,  0.0178,  0.0201,  ...,  0.0041,  0.0070,  0.0026],\n",
       "                      [-0.0079, -0.0074,  0.0060,  ..., -0.0023,  0.0084,  0.0057],\n",
       "                      [ 0.0161, -0.0234,  0.0041,  ..., -0.0287, -0.0007,  0.0020]],\n",
       "                     device='cuda:0')),\n",
       "             ('pro_fc_g2.bias',\n",
       "              tensor([-0.0153, -0.0031,  0.0089,  0.0116, -0.0046,  0.0023, -0.0238,  0.0057,\n",
       "                      -0.0200, -0.0287, -0.0012, -0.0083, -0.0189, -0.0303, -0.0310,  0.0213,\n",
       "                       0.0161, -0.0156, -0.0053, -0.0162, -0.0247, -0.0309, -0.0026,  0.0265,\n",
       "                      -0.0039, -0.0269,  0.0074, -0.0177,  0.0227,  0.0172,  0.0229, -0.0201,\n",
       "                      -0.0250, -0.0202,  0.0127, -0.0286,  0.0120,  0.0147, -0.0300,  0.0297,\n",
       "                      -0.0295, -0.0161,  0.0112,  0.0271, -0.0063,  0.0025, -0.0222, -0.0117,\n",
       "                      -0.0253,  0.0087, -0.0155,  0.0226, -0.0017,  0.0141, -0.0117,  0.0071,\n",
       "                      -0.0289, -0.0307,  0.0273, -0.0297, -0.0199, -0.0124, -0.0195, -0.0063,\n",
       "                      -0.0106, -0.0085,  0.0163,  0.0145,  0.0170,  0.0002, -0.0254, -0.0162,\n",
       "                       0.0174,  0.0136,  0.0003,  0.0197, -0.0065, -0.0158, -0.0056, -0.0232,\n",
       "                       0.0273,  0.0189, -0.0119,  0.0037, -0.0157,  0.0281, -0.0264,  0.0290,\n",
       "                      -0.0083, -0.0253, -0.0117,  0.0085, -0.0239,  0.0235,  0.0297, -0.0215,\n",
       "                      -0.0260,  0.0062,  0.0152,  0.0105, -0.0013, -0.0168,  0.0061,  0.0077,\n",
       "                       0.0189, -0.0169,  0.0140,  0.0144,  0.0228,  0.0279,  0.0124, -0.0069,\n",
       "                       0.0072, -0.0004,  0.0113,  0.0234,  0.0053,  0.0066, -0.0019, -0.0308,\n",
       "                      -0.0280, -0.0169,  0.0291,  0.0106,  0.0147,  0.0099, -0.0190,  0.0112],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0610,  0.0050,  0.0497,  ..., -0.0632,  0.0255,  0.0934],\n",
       "                      [ 0.0171,  0.0175, -0.0302,  ..., -0.0464, -0.0132,  0.0559],\n",
       "                      [-0.0142,  0.0384, -0.0225,  ..., -0.0205,  0.0425,  0.0192],\n",
       "                      ...,\n",
       "                      [ 0.0252,  0.0089, -0.0399,  ..., -0.0152,  0.0382,  0.0288],\n",
       "                      [ 0.0186,  0.0118,  0.0351,  ...,  0.0077,  0.0444, -0.0262],\n",
       "                      [ 0.1130, -0.0078, -0.1447,  ...,  0.4439,  0.2275,  0.4396]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0845, -0.0550, -0.0267,  ..., -0.0194, -0.0868, -0.0833],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 2.7073e-02,  2.3518e-02, -4.9343e-03,  ..., -1.1136e-02,\n",
       "                       -6.7214e-02,  2.2162e-01],\n",
       "                      [ 2.0583e-02, -2.7722e-02, -1.7555e-02,  ...,  2.2232e-02,\n",
       "                       -4.8546e-02, -1.0348e-01],\n",
       "                      [-2.7797e-02, -1.7806e-02,  2.4604e-02,  ...,  1.5902e-03,\n",
       "                        1.5925e-02, -6.4761e-01],\n",
       "                      ...,\n",
       "                      [-3.2354e-02, -2.3851e-02,  1.0631e-02,  ...,  9.8529e-03,\n",
       "                        1.8862e-02, -1.3297e-01],\n",
       "                      [ 8.0578e-03,  8.1125e-03,  2.0540e-02,  ...,  7.6866e-03,\n",
       "                       -5.4303e-04, -2.4512e-01],\n",
       "                      [-2.8004e-02,  3.5679e-02,  4.3635e-02,  ...,  3.1486e-03,\n",
       "                        6.1821e-02, -3.3354e-01]], device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([-2.5092e-01,  3.8103e-02, -2.9695e+00, -1.4792e+00, -5.4780e-01,\n",
       "                      -4.8819e-01, -2.6044e-01,  9.6665e-03, -1.9369e-01, -8.2647e-01,\n",
       "                       1.2833e-02, -2.5074e-01, -5.2113e-01, -1.3229e-01, -3.2487e+00,\n",
       "                       7.0027e-02,  9.1415e-03,  7.3304e-01, -1.0386e+00, -6.8677e-03,\n",
       "                      -3.2639e-01, -2.4123e-02, -5.7654e-01, -1.1121e+00,  7.1503e-02,\n",
       "                       3.6710e-03, -1.7949e-02, -6.8016e-01, -4.9031e-01, -3.6446e-02,\n",
       "                      -2.4427e-01, -1.7215e-01, -1.4865e-02,  1.0175e-01, -3.6240e-03,\n",
       "                      -1.6621e-02, -4.7259e-01, -3.0161e+00, -1.7377e-01, -7.5063e-01,\n",
       "                      -3.6639e-01, -3.5122e-01, -2.2953e-01, -2.9522e+00,  1.4744e-01,\n",
       "                      -5.8200e-01, -8.7728e-02, -7.1252e-01,  1.4884e-02,  8.9419e-01,\n",
       "                      -7.4992e-01, -2.5333e+00, -2.7455e-01, -6.8401e-01, -1.9430e+00,\n",
       "                      -3.7653e-01,  1.0008e+00, -3.1872e+00, -2.5170e+00, -2.1807e+00,\n",
       "                      -6.3541e-01, -2.7264e+00, -3.6755e-02, -5.0757e-02, -3.2455e+00,\n",
       "                      -5.8112e-01, -5.4194e-01,  7.4150e-01, -2.5946e-01, -5.5170e-01,\n",
       "                       1.0343e-01, -4.3281e-02, -7.8209e-01, -8.6207e-02, -3.8126e-01,\n",
       "                      -2.9437e+00,  6.5716e-02, -7.1325e-01, -4.4054e-02, -2.8567e+00,\n",
       "                       5.3248e-03, -5.8074e-01, -4.8115e-02, -5.0964e-01, -3.8899e-01,\n",
       "                      -5.7952e-01, -5.5523e-01, -5.4599e-01, -7.1628e-01,  7.4461e-03,\n",
       "                      -2.7350e-01, -1.1027e-01, -4.4214e-01, -2.5848e+00,  1.4725e-02,\n",
       "                      -2.1045e-01, -3.3264e+00, -6.8490e-02, -2.7864e-02, -4.8165e-01,\n",
       "                      -8.5311e-02, -7.9146e-03,  4.8079e-02, -6.5264e-01,  2.2626e-01,\n",
       "                      -5.9699e-02, -3.9206e-01, -2.9226e-01, -6.2582e-01, -2.0335e+00,\n",
       "                      -2.8224e+00, -7.8573e-02, -3.6944e-01, -6.0266e-01,  8.4941e-02,\n",
       "                      -2.0347e-01, -3.7529e-01, -2.7363e-01,  6.4057e-02, -3.1770e+00,\n",
       "                      -2.7649e-01, -8.5634e-01, -5.4368e-01, -1.3433e-01, -2.3837e+00,\n",
       "                      -7.8461e-02, -3.7899e-01,  1.0216e-01, -2.6597e-01, -4.3355e-01,\n",
       "                      -1.4954e-01, -2.1819e+00, -7.6764e-02, -2.7409e-01, -2.9938e-02,\n",
       "                      -1.0155e+00, -4.9365e-01, -4.5676e-01,  2.6111e-01, -1.4987e-01,\n",
       "                      -7.9500e-01, -3.1274e-02, -2.4686e-01,  6.3633e-02, -5.0635e-01,\n",
       "                      -2.7683e+00, -7.0142e-01, -8.6590e-01, -9.4149e-02, -3.1101e+00,\n",
       "                      -6.3727e-01, -2.9895e-02, -6.9078e-01, -2.6894e-01, -2.1812e-01,\n",
       "                       9.7351e-01, -6.0271e-01,  2.8730e-02, -3.8813e-01, -5.0090e-02,\n",
       "                      -9.4410e-02, -1.9478e+00, -2.5821e-02,  2.7503e-02,  8.2500e-02,\n",
       "                       9.0602e-02,  8.7584e-02,  8.3044e-02,  9.3262e-02, -5.0538e-01,\n",
       "                      -1.4608e-01, -1.4012e+00,  7.9683e-02, -9.8251e-01, -8.3325e-02,\n",
       "                      -2.6567e-03, -2.2614e+00, -2.9392e-03, -1.2951e+00,  6.6118e-02,\n",
       "                      -5.0425e-03, -2.3466e+00, -3.3440e-01, -6.4186e-01, -8.1319e-01,\n",
       "                      -2.0752e-01, -4.8365e-01,  1.8279e-02, -6.6917e-02, -1.7821e-02,\n",
       "                      -2.8399e-01,  4.4162e-02, -2.4227e+00, -9.2421e-01, -2.8827e-01,\n",
       "                      -6.8735e-01,  9.5361e-02, -6.2113e-01, -2.2737e+00, -1.8395e+00,\n",
       "                      -5.5427e-01, -6.1332e-02, -3.1106e+00, -4.2981e-01, -6.2599e-01,\n",
       "                      -1.5375e-02, -2.0982e-01, -7.1042e-01, -7.1599e-01, -1.8061e+00,\n",
       "                       1.0511e-02, -5.7987e-01, -2.1167e+00, -1.1549e-01, -1.5546e-02,\n",
       "                       8.7605e-02, -6.7921e-01,  6.7147e-03, -3.2029e+00, -7.3469e-01,\n",
       "                      -3.1034e-01, -4.5348e-01, -2.6472e-01, -2.2668e-01, -1.6047e-02,\n",
       "                       3.7503e-02, -3.3252e-01, -3.9323e-02,  1.2071e-01,  7.5321e-02,\n",
       "                      -4.6000e-01, -1.9207e-01, -3.3942e-01, -1.4478e+00, -7.7638e-01,\n",
       "                       5.4631e-01, -6.7498e-01,  1.3021e-01, -7.1853e-01, -6.5496e-03,\n",
       "                      -1.7407e-02, -8.6404e-01, -9.0937e-01, -3.9757e-01, -2.7250e-01,\n",
       "                      -2.5607e+00, -8.0620e-01, -1.1062e-01, -8.2119e-02, -1.2849e-01,\n",
       "                       6.0064e-02, -4.3527e-01, -5.5956e-01,  1.0848e-01, -4.1014e-02,\n",
       "                      -2.4046e+00, -1.8637e-02, -2.4485e-01, -4.5230e-01, -3.7826e-03,\n",
       "                       5.5499e-03,  6.8173e-02, -6.6128e-03, -3.6034e-03,  6.0069e-01,\n",
       "                      -1.3944e-01,  5.4743e-02, -2.7827e+00, -1.5719e-01, -2.3183e+00,\n",
       "                      -3.2643e-01, -1.0620e+00,  3.6604e-02, -1.3866e-02, -6.8136e-01,\n",
       "                       1.1388e-02, -9.2547e-01, -6.3068e-02, -2.2343e-01, -2.2427e-01,\n",
       "                      -2.8898e+00, -5.7394e-01,  1.6412e-01, -2.2936e+00,  9.4322e-02,\n",
       "                      -7.0796e-02, -5.4199e-01, -1.5751e+00, -6.4505e-01, -8.4301e-01,\n",
       "                      -4.5704e-01, -3.2662e-02, -3.8410e-02, -3.3281e+00,  4.5584e-01,\n",
       "                      -7.1649e-03,  7.3996e-02, -1.4657e+00, -2.0814e-01, -4.3134e-03,\n",
       "                      -4.6416e-02,  1.6892e-03,  2.4928e-02, -5.0887e-03, -5.6251e-01,\n",
       "                      -1.5532e-02,  2.1756e-02, -2.6382e+00, -3.7000e-02, -4.1645e-01,\n",
       "                      -4.8645e-01, -7.1679e-01, -3.9877e-02,  7.1981e-01, -4.5065e-01,\n",
       "                       8.9498e-03, -5.7302e-01, -3.1611e-01, -7.1799e-01, -2.5940e-01,\n",
       "                      -3.5783e-01, -6.9280e-01, -5.3302e-02, -2.9410e-01,  5.7109e-02,\n",
       "                      -9.0477e-01, -2.3398e+00, -1.1192e-01, -1.4922e-02, -4.9468e-01,\n",
       "                      -8.5714e-01, -2.9136e-02, -2.6219e+00, -5.5496e-01,  1.4908e-01,\n",
       "                      -2.0974e+00, -1.0006e-01, -1.3229e-01, -8.2150e-01, -4.5928e-02,\n",
       "                       3.5832e-01, -6.3263e-01, -2.5022e+00, -9.7078e-02, -5.3638e-02,\n",
       "                       6.3586e-04, -9.5743e-01, -5.0223e-01, -1.9417e-03,  7.3861e-02,\n",
       "                      -4.3011e-03, -9.9179e-01, -3.1129e+00, -5.4845e-01, -2.6356e+00,\n",
       "                       7.0771e-01, -1.0205e-02, -4.6857e-01, -2.7749e-01, -1.3967e-01,\n",
       "                      -2.3783e-01, -2.6363e-01, -8.9947e-01,  4.0884e-03, -2.1761e+00,\n",
       "                       1.2312e-03, -3.0757e-01, -2.8252e-01, -8.7041e-01, -3.1177e+00,\n",
       "                      -2.4178e-01,  1.8243e-01, -5.8695e-02, -9.1238e-01, -3.1072e-02,\n",
       "                      -2.9451e+00,  9.5380e-02,  6.4199e-02, -4.7183e-01, -6.5461e-01,\n",
       "                      -7.2880e-01, -5.0205e-01, -5.1944e-03, -1.2593e+00, -5.6894e-03,\n",
       "                       6.7609e-02, -8.1673e-01, -2.4668e+00, -1.2482e+00,  1.2605e-01,\n",
       "                      -7.0015e-01, -6.7764e-04, -1.3093e-01, -5.2999e-01, -2.6197e+00,\n",
       "                       5.5890e-01,  1.7778e-01, -4.8192e-01, -6.2776e-01, -3.0598e-01,\n",
       "                      -2.9921e-03, -6.5015e-01,  1.3633e-02, -5.3162e-01, -2.4393e+00,\n",
       "                      -5.8544e-01, -2.0759e-01, -2.3807e+00, -4.1575e-02, -2.3407e-01,\n",
       "                      -7.7956e-01, -2.4350e-02, -1.9105e-01,  9.1348e-03, -2.1378e-02,\n",
       "                      -3.0335e-01,  1.0127e+00, -1.5700e-01, -4.3417e-01, -1.7217e+00,\n",
       "                      -5.4823e-03, -6.0671e-01, -3.2559e-01,  1.5573e-03, -6.2792e-01,\n",
       "                      -1.4572e-02,  4.6722e-02,  1.1263e+00, -4.2097e-03, -3.3695e-02,\n",
       "                       2.7767e-02, -4.6015e-02,  2.4948e-02, -1.8102e-01, -2.4160e-02,\n",
       "                      -2.8549e-02, -8.3274e-02, -6.9257e-01, -2.3087e-01, -6.5091e-01,\n",
       "                      -2.5275e+00, -2.5306e-01, -4.9352e-03, -1.9836e-03, -6.6821e-01,\n",
       "                      -4.4163e-01, -1.5879e-02, -2.6807e-03, -2.7520e+00, -2.2087e-01,\n",
       "                      -3.2262e+00, -1.4440e-01, -1.8411e+00, -1.7974e-02, -6.3378e-01,\n",
       "                      -4.3638e-03, -5.2093e-02, -2.3148e+00,  7.0571e-02, -1.0254e-02,\n",
       "                      -5.7658e-01, -2.7659e-02,  4.9012e-01, -5.1561e-01, -6.7620e-01,\n",
       "                      -2.0229e-01, -5.6088e-01, -3.0882e-04, -8.8120e-01, -2.5061e-01,\n",
       "                      -2.0904e+00, -1.1893e-01, -7.1337e-01, -5.8639e-01,  9.4025e-01,\n",
       "                       1.1219e-02, -9.6051e-04, -9.9784e-01, -3.1147e-02, -1.2129e-01,\n",
       "                      -2.7012e+00, -2.7834e-01, -2.9717e-01, -2.3901e+00,  5.7201e-02,\n",
       "                       4.5209e-02, -5.2463e-01, -6.9149e-01, -4.1401e-01, -5.6395e-01,\n",
       "                      -5.0879e-01, -1.0190e+00, -3.7234e-01, -1.6036e-01,  1.3564e-02,\n",
       "                      -3.0415e-01, -7.0203e-01, -1.7057e-01, -1.5888e-01, -2.8730e+00,\n",
       "                      -8.7083e-03, -2.9878e+00, -2.5536e+00, -2.9682e+00, -3.0538e+00,\n",
       "                      -1.5083e-02, -3.6600e+00, -4.7587e-01, -6.5379e-04,  3.4281e-02,\n",
       "                      -8.0148e-01, -5.8906e-02], device='cuda:0')),\n",
       "             ('out.weight',\n",
       "              tensor([[-0.1363, -0.0600, -0.0671, -0.0995,  0.0536,  0.0151,  0.0104,  0.0101,\n",
       "                        0.0123,  0.0382,  0.0169,  0.0170,  0.0657,  0.0366, -0.0620, -0.0520,\n",
       "                        0.0112, -0.0156, -0.0713,  0.0107,  0.0189,  0.0074,  0.0478,  0.0109,\n",
       "                       -0.0312,  0.0148,  0.0124,  0.1192,  0.0733,  0.0181,  0.0169,  0.0185,\n",
       "                        0.0077, -0.0351,  0.0122,  0.0133,  0.0746, -0.0571,  0.0111,  0.0486,\n",
       "                       -0.0870,  0.0183,  0.0190, -0.0690,  0.0018,  0.0653,  0.0227,  0.0220,\n",
       "                        0.0163, -0.0154,  0.0262, -0.0874,  0.0077,  0.0330, -0.0511,  0.0326,\n",
       "                       -0.0128, -0.0652, -0.1116, -0.0618,  0.0429, -0.0705,  0.0168,  0.0130,\n",
       "                       -0.0806,  0.0506,  0.0255, -0.0243,  0.0022,  0.0314,  0.0135,  0.0084,\n",
       "                        0.0600,  0.0080,  0.0332, -0.0566,  0.0110,  0.0750,  0.0161, -0.0540,\n",
       "                        0.0154,  0.0279,  0.0168,  0.0367,  0.0062,  0.0300,  0.0557,  0.0262,\n",
       "                        0.0779,  0.0160,  0.0158,  0.0158,  0.0366, -0.0839,  0.0161,  0.0170,\n",
       "                       -0.0561,  0.0091,  0.0120,  0.0125,  0.0202,  0.0144,  0.0168, -0.2001,\n",
       "                       -0.0438,  0.0054,  0.0310,  0.0303,  0.0204, -0.1188, -0.0560,  0.0188,\n",
       "                        0.0099,  0.0286, -0.0930,  0.0144,  0.0431,  0.0049, -0.1148, -0.0596,\n",
       "                        0.0237,  0.0297,  0.0403, -0.0903, -0.0683,  0.0125,  0.0161, -0.0457,\n",
       "                        0.0376,  0.0417,  0.0200, -0.0716,  0.0201,  0.0185,  0.0148,  0.1178,\n",
       "                        0.0211,  0.0252, -0.0240,  0.0179,  0.0501,  0.0128,  0.0147, -0.0457,\n",
       "                        0.0117, -0.0797,  0.0465,  0.0448,  0.0068, -0.0677,  0.0344,  0.0148,\n",
       "                        0.0355,  0.0167,  0.0173, -0.0151,  0.0250, -0.0594,  0.0406,  0.0218,\n",
       "                        0.0127, -0.0505,  0.0120,  0.0091, -0.0595, -0.0285, -0.0599,  0.0107,\n",
       "                        0.0230,  0.0805,  0.0156,  0.2182,  0.0141,  0.0802,  0.0251,  0.0119,\n",
       "                       -0.1047,  0.0100,  0.0655, -0.0504,  0.0184, -0.0975,  0.0202,  0.1406,\n",
       "                        0.0657,  0.0113,  0.0422,  0.0168,  0.0226,  0.0193,  0.0192,  0.0149,\n",
       "                       -0.1100,  0.0392,  0.0183,  0.0347, -0.0966,  0.0400, -0.0934, -0.0998,\n",
       "                        0.0139,  0.0178, -0.0590,  0.0470,  0.0496,  0.0184,  0.0103,  0.0786,\n",
       "                        0.0218, -0.0488,  0.0204,  0.0234, -0.0896, -0.1287,  0.0166, -0.0939,\n",
       "                        0.0516,  0.0110, -0.0689,  0.0897,  0.0217,  0.0148,  0.0129,  0.0162,\n",
       "                       -0.0704,  0.0094,  0.0152,  0.0068,  0.0028,  0.0071,  0.0309,  0.0338,\n",
       "                        0.0188, -0.0787,  0.0534, -0.0236,  0.0519,  0.0123,  0.0351,  0.0178,\n",
       "                        0.0141,  0.1403,  0.0686,  0.0327,  0.0125, -0.1176,  0.0755,  0.0197,\n",
       "                        0.0126, -0.0306, -0.0747,  0.0091,  0.0398, -0.0438,  0.0164, -0.0452,\n",
       "                        0.0236,  0.0285,  0.0405,  0.0177,  0.0069,  0.0127,  0.0139,  0.0197,\n",
       "                       -0.0111,  0.0183, -0.0883, -0.1232,  0.0163, -0.0705,  0.0171,  0.0532,\n",
       "                       -0.0605,  0.0178,  0.0595,  0.0127,  0.1305,  0.0073,  0.0280,  0.0177,\n",
       "                       -0.0681,  0.0381, -0.0090, -0.1182, -0.0785,  0.0075,  0.0360, -0.0487,\n",
       "                        0.0391,  0.0538,  0.0343,  0.0209,  0.0198, -0.0552, -0.0115,  0.0115,\n",
       "                       -0.0460, -0.0532, -0.1129,  0.0446,  0.0174,  0.0190,  0.0110,  0.0091,\n",
       "                        0.0144,  0.0155,  0.0097, -0.0519,  0.0160,  0.0139,  0.0236,  0.0537,\n",
       "                        0.0182, -0.0214,  0.0273,  0.0164,  0.0408,  0.0220,  0.0539,  0.0253,\n",
       "                        0.0133,  0.0320,  0.0076,  0.0128, -0.0444,  0.0782, -0.0513,  0.0129,\n",
       "                        0.0133,  0.0736,  0.1138,  0.0123, -0.0578,  0.0142,  0.0188, -0.1083,\n",
       "                        0.0140, -0.1042,  0.1032,  0.0057, -0.0260,  0.0661, -0.1059,  0.0102,\n",
       "                       -0.0707,  0.0223,  0.1268,  0.0147,  0.0170, -0.0380,  0.0160,  0.0421,\n",
       "                       -0.0577,  0.0553, -0.0714, -0.0180,  0.0094,  0.0265,  0.0148, -0.0785,\n",
       "                        0.0158,  0.0195, -0.0401,  0.0120, -0.0891,  0.0164,  0.0154,  0.0082,\n",
       "                        0.0652, -0.0510,  0.0215, -0.0618,  0.0070,  0.0326,  0.0141, -0.0663,\n",
       "                        0.0158, -0.0534,  0.0328,  0.0297,  0.0475,  0.0452,  0.0052,  0.0943,\n",
       "                        0.0110,  0.0096,  0.0262, -0.1154, -0.0615,  0.0120,  0.0481,  0.0121,\n",
       "                        0.0183,  0.0360, -0.0901, -0.0251, -0.0014,  0.0277,  0.0448, -0.0176,\n",
       "                        0.0238,  0.0661,  0.0216,  0.0238, -0.0602,  0.0885,  0.0181, -0.0625,\n",
       "                        0.0090,  0.0103,  0.0876,  0.0170,  0.0183,  0.0186,  0.0195,  0.0209,\n",
       "                       -0.0173,  0.0119,  0.1014,  0.1249,  0.0221,  0.0366,  0.0081,  0.0164,\n",
       "                        0.0555,  0.0103, -0.0539, -0.0102,  0.0066,  0.0142,  0.0105,  0.0110,\n",
       "                        0.0073,  0.0096,  0.0061,  0.0191,  0.0137,  0.0592,  0.0169,  0.1079,\n",
       "                       -0.0755,  0.0143,  0.0149,  0.0395,  0.0413,  0.0179,  0.0108,  0.0135,\n",
       "                       -0.0771,  0.0118, -0.0611,  0.0129, -0.1549,  0.0114,  0.0514,  0.0148,\n",
       "                        0.0184, -0.0547, -0.0763,  0.0113,  0.0390,  0.0107, -0.0313,  0.0228,\n",
       "                        0.0437, -0.0559,  0.0565,  0.0047,  0.0822,  0.0155, -0.0676, -0.0844,\n",
       "                        0.0583,  0.0404, -0.0132,  0.0136,  0.0113,  0.0502,  0.0210,  0.0254,\n",
       "                       -0.0777,  0.0166,  0.0214, -0.0440,  0.0195,  0.0108,  0.0394, -0.0517,\n",
       "                        0.0256,  0.0300,  0.0147,  0.0721,  0.0238,  0.0152,  0.0156,  0.0068,\n",
       "                        0.0342,  0.0186,  0.0147, -0.0467,  0.0143, -0.0363, -0.0616, -0.0653,\n",
       "                       -0.0497,  0.0061,  0.0447,  0.0068,  0.0148,  0.0247,  0.0239,  0.0102]],\n",
       "                     device='cuda:0')),\n",
       "             ('out.bias', tensor([2.2095], device='cuda:0'))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('saved_models/esm-2-stitch-0.05_validation_fully_optimized.pt')['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'epoch':epoch,\n",
    "#     'model_state_dict':model.state_dict(),\n",
    "#     'optimizer_state_dict':optimizer.state_dict()\n",
    "# },'saved_models/esm-2-stitch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('saved_models/esm-2-stitch.pt')['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "Make prediction for 440786 samples...\n",
      "metrics for  Stitch\n",
      "cindex2 0.7394952272944774\n",
      "mse: 1.0202613\n",
      "pearson 0.6929313903787505\n",
      "Stitch\n",
      "  mse:1.0202613  pearson:0.6929313903787505  ci:0.7394952272944774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0202613, 0.7394952272944774, 0.6929313903787505)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Y, P = predicting(model, device, test_loader)\n",
    "calculate_metrics(Y, P, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: davis\n",
      "cuda_name: cuda:0\n",
      "dataset: davis\n",
      "test entries: 5010 effective test entries 5010\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m TEST_BATCH_SIZE \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m'''models_dir = 'models'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mresults_dir = 'results'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mmodel.to(device)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mmodel.load_state_dict(torch.load(model_file_name, map_location=cuda_name))'''\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m test_data \u001b[39m=\u001b[39m create_dataset_for_test(dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m test_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(test_data, batch_size\u001b[39m=\u001b[39mTEST_BATCH_SIZE, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                                           collate_fn\u001b[39m=\u001b[39mcollate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dagaa/Projects/sample_project/generative_modelling/DGraphDTA/load_dataset.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m Y, P \u001b[39m=\u001b[39m predicting(model, device, test_loader)\n",
      "File \u001b[0;32m~/Projects/sample_project/generative_modelling/DGraphDTA/data_process.py:310\u001b[0m, in \u001b[0;36mcreate_dataset_for_test\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_target(key, dataset):  \u001b[39m# ensure the contact and aln files exists\u001b[39;00m\n\u001b[1;32m    309\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     g \u001b[39m=\u001b[39m target_to_graph(key, proteins[key], contac_path, msa_path)\n\u001b[1;32m    311\u001b[0m     target_graph[key] \u001b[39m=\u001b[39m g\n\u001b[1;32m    313\u001b[0m \u001b[39m# count the number of  proteins with aln and contact files\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/sample_project/generative_modelling/DGraphDTA/data_process.py:215\u001b[0m, in \u001b[0;36mtarget_to_graph\u001b[0;34m(target_key, target_sequence, contact_dir, aln_dir)\u001b[0m\n\u001b[1;32m    213\u001b[0m index_row, index_col \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(contact_map \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(index_row, index_col):\n\u001b[0;32m--> 215\u001b[0m     target_edge_index\u001b[39m.\u001b[39mappend([i, j])\n\u001b[1;32m    216\u001b[0m target_feature \u001b[39m=\u001b[39m target_to_feature(target_key, target_sequence, aln_dir)\n\u001b[1;32m    217\u001b[0m target_edge_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(target_edge_index)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = datasets[2]  # dataset selection\n",
    "    model_st = GNNNet.__name__\n",
    "    print('dataset:', dataset)\n",
    "\n",
    "    cuda_name = 'cuda:0'\n",
    "    print('cuda_name:', cuda_name)\n",
    "\n",
    "    TEST_BATCH_SIZE = 512\n",
    "    '''models_dir = 'models'\n",
    "    results_dir = 'results'\n",
    "\n",
    "    device = torch.device(cuda_name if torch.cuda.is_available() else 'cpu')\n",
    "    model_file_name = 'models/model_' + model_st + '_' + dataset + '.model'\n",
    "    result_file_name = 'results/result_' + model_st + '_' + dataset + '.txt'\n",
    "\n",
    "    model = GNNNet()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_file_name, map_location=cuda_name))'''\n",
    "    test_data = create_dataset_for_test(dataset)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                              collate_fn=collate)\n",
    "\n",
    "    Y, P = predicting(model, device, test_loader)\n",
    "    calculate_metrics(Y, P, dataset)\n",
    "    # plot_density(Y, P, fold, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('graphdta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "484888acb7f4fd6115c2ddd024bc38be5ea78934e727c7c21c6a08eedf2692cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
